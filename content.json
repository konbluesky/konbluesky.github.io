{"posts":[{"title":"Carry-Coin 一个自动化搬砖套利平台","text":"Carry-Coin 是一个套利程序，程序从23年初开始开发至今，目前已经基本稳定，现在将程序的设计整理出来；套利思路很简单：程序监控Cex和Dex平台，针对同一币种发现差价后自动化搬运；1234567891011121314- carry-config-generator(python) - 框架:web3,pandas ; 工程主要负责根据dex,cex，第三方：1inch,odos,dexscreener 数据，进行数据分析最终生成套利配置；- carry-core (Java) - 一个基于Java的套利核心程序，dex&lt;-&gt;cex套利逻辑的顶层抽象,SwapEngine，SwapStategy, ArbitrageProcessor,CenterExchange,DecenterExchanage,SwapProtocol 等;- carry-worker (Java) - 框架:Springboot3.2.5,Xchange,Web3j,RxJava3,Guava等；工程基于core实现的不同dex,cex的监控、告警、通知、搬运、买卖逻辑；- carry-protocol-adapter(Nodejs) - 基于Uniswap-sdk ,jupiter-swap-api(solana)开发的套利协议适配器，适配v2/v3询价；- carry-web-front (Nodejs) - Vue3.0+TypeScript+Vite5+Ant-Design-Vue等，工程主要管理平台的前端页面，包括套利开关、线上配置、交易数据监控，链上数据监控报表等；- carry-web-server (Java) - 框架: Spring Cloud Alibaba, Mysql, 管理平台的后端服务； 部署架构 程序截图 技术栈语言 Java 11 Python Nodejs Bash Shell 框架Java Spring Boot JPA Xchange RxJava Guava transmittable-thread-local fastjson web3j lombok assertj jasypt Hutool Slf4j、Logback Python Flask pickledb web3 pandas Nodejs pm2 uniswap-core,V2/v3-sdk solana/web3、spl-token nestjs ethers.js 平台 jeecg-boot","link":"/2024/10/13/carry_coin_architecture_1/"},{"title":"Carry-Coin 架构设计 Core模块(1)","text":"Core组成部分Swap基本概念 SwapEngine 套利引擎，内部独立线程，Handler执行 ，Center构建,Job注册 SwapEngine最初设计可以支持dex(n)&lt;-&gt;cex(n),目前阶段仅SingleSwapEngine 实现了dex(1，n)&lt;-&gt;cex(1)的套利动作,即一个Engine绑定1个cex和N个dex； SwapContext(标记接口) SwapContext是SwapEngine的上下文，是个巨型类，为了跨交易所共用上下文预留的,主要是保存SwapEngine运行时的数据，包含了所有重要对象的引用：交易所信息，交易对信息，交易所账户信息; SwapConfig SwapConfig是SwapEngine的配置类，主要是保存SwapEngine运行时所需的配置信息; SwapHandler 用来初始化Context，同步job的阻塞加载，异步job的注册，BizDataLoaderContext首次初始化和校验 SwapInitializerConfig 根据yml初始化SwapLauncher来触发Engine工作； SwapLauncher 交易引擎启动器 Center Cex中心交易所相关的抽象和套利动作 CenterExchangeHolder 中心交易所的顶级抽象，主要是一些技术动作： 注册同步和异步的取数器（Job），获取Context数据等动作 交易所支持同步和异步取数两种模式，同步在SwapEngine初始化时执行一次，异步周期性运行； 周期性执行使用ScheduledExecutorService，实现使用了alibaba的transmittable-thread-local库，主要目的解决异步执行时上下文传递的问题； Job方式取来的数据都会放在BizDataLoaderContext容器中； AbstractCenterExchangeHolder 对CenterExchangeHolder的基本实现 CenterExchangeHolderBehavior 业务动作抽象接口：Limit/Marker下单，撤单，获取订单状态，提现，转账等业务动作,这个接口也是pipeline和job中操作Cex的核心，非必要业务流中不操作CenterExchangeHolder,AbstractCenterExchangeHolder这种顶级接口； Cex交易所操作使用Xchange完成; FacilitySupport 提供一套基本的Cex实现模板 CenterSymbolInfo Cex侧套利相关配置信息 Decenter Dex去中心交易平台相关的抽象, Decenter.protocol Decenter中SwapProtocol协议抽象，目前已实现包含solana,bsc链，odos,zerox平台的询价、交易动作;设计过程中难点在于对不同链的交易动作进行同一视角进行抽象和设计； EVM部分 GenericWeb3jBehavior 链上动作的通用抽象，默认只实现getNetwork,getWeb3jManager,考虑到多链支持Client客户端不定，所以作为泛型传入； 必要动作queryTxConfirmed,getRawAmountOut,getBalanceOfNode做抽象方法，考虑到这几个方法不挑网络，入参回参明确，所以放在此处； 不同链差异化动作放在下层实现. EthGenericWeb3jBehavior 具象evm链的实现，主要是实现网络层面、Token层面的一些方法了allowance, getTransactionGasLimit, signTransaction, waitTxConfirmed, queryTxConfirmed, getNonce, getBalanceOfNode, tokenTransfer, getGasProvider, gasProvider GenericSwapV2Impl,GenericSwapV3Impl 基于EthGenericWeb3jBehavior完成Dex swap全过程的方法,包含：getAmountsOut,swapExactTokensForTokens，swapExactTokensForTokensSupportingFeeOnTransferTokens getRawAmountOut区别于getAmountsOut，是用来通过evm中log数据获取最终交换到的token数量； SwapExactTForTParam 上层通过该类传入swap所需参数； Solana部分ODOS部分Strategy 交易策略 swap 套利动作","link":"/2024/10/14/carry_coin_architecture_2/"},{"title":"Carry-Coin 架构设计 Core模块(2)","text":"Action 组成部分 AbstractForwardPipeline 正向套利(cex-&gt;dex)流水线抽象类 AbstractReversePipeline 逆向套利(dex-&gt;cex)流水线抽象类 CommonCutOffForwardPipeline CommonLimitWaitForwardPipeline CommonReversePipeline DebugReversePipeline WithdrawAndSellPipeline Cex账户留币策略时触发：当账户留币且链上价格比交易所高时，提现-&gt;dex-&gt;卖出 DepositAndSellPipeline Dex留币策略触发：钱包中留币且交易所价格大于链上：充币-&gt;cex-&gt;卖出 OnlySwapInChainPipeline Dex留币策略触发：钱包中留币且链上价格高于Cex：卖出 SolanaReversePipeline Solana逆向套利流水线 TransactionRecordFactory Job 组成部分 异步任务，优先使用websocket取数，如cex不支持则使用rest方式，rest调用一定要实现限频策略，具体见Xchange BalanceRest200msJob 每200ms 调rest接口取余额； ChainAccountMonitor10mJob 每10分钟 监控链上账户余额； CleanBalance1mJob 每1分钟 扫描账户符合条件触发留币策略 ConsumerMiddleCoinBuyAndSellJob 三角套利时，中间币消耗情况入库，订阅的交易所购买中间币（目前BNB,SOL） FundingRecordRest200msJob 每200ms 调rest接口取充提记录监控充提状态； LoaderDataContextMonitor1sJob 最初构想用来存储下单时，当前depth,ticker,orderbook等数据，数据量太大，有条件的情况下上nosql, 就不入db了； PendingPlaceOrderJob 定时扫描未完成订单，并尝试重试 ResetSymbolConfigJob 重置套利币本配置 RiseMonitorRest10sJob SelfOrderRest100msJob","link":"/2024/10/15/carry_coin_architecture_3/"},{"title":"Carry-Coin 中 Jasypt 的应用","text":"自从最近L君小弟电脑中毒，疑似私钥泄漏，导致3W u被盗，程序一直以来裸奔的状态下，再次让我菊花一紧。于是，我开始了对Spring Boot的jasypt加密配置的研究。 最坏情况服务器即使被黑，也要尽可能保证程序的安全。 配置文件中关键信息： 交易所token，钱包私钥加密； jar中yml打包时排除，服务器上用密文配置执行； 解密密码动态设置； jasypt 集成程序引入pom.xml 12345 &lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt;&lt;/dependency&gt; application.yml 123jasypt: encryptor: password: ${JASYPT_ENCRYPTOR_PASSWORD} Application.java 12345678910111213141516171819202122/** * &lt;p&gt; @Date : 2023/3/19 &lt;/p&gt; * &lt;p&gt; @author konbluesky &lt;/p&gt; */@SpringBootApplication(scanBasePackages = &quot;com.block&quot;)@EnableScheduling@EnableAsync@EnableJpaAuditing// WARN bad smell@EncryptablePropertySources({ @EncryptablePropertySource(value = &quot;file:./config/application.yml&quot;,ignoreResourceNotFound = true), @EncryptablePropertySource(value = &quot;classpath:application.yml&quot;,ignoreResourceNotFound = true)})@EnableEncryptablePropertiespublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 打包排除pom.xml,设置打包时排除yml文件，避免铭文yml误打包到jar中 123456789101112 &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;!-- 用springboot 打包时 排除yml--&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt;&lt;/resources&gt; 启动脚本原启动方式需要通过-Djasypt.encryptor.password=”the password”,来设置加密密码。这种方式用jps -mlv可以看到启动命令，但是这种方式不安全，依然容易泄露密码。为了安全起见，我们需要在启动脚本中设置环境变量 JASYPT_ENCRYPTOR_PASSWORD 来加密配置文件中的敏感信息。设置后又担心环境变量被echo出来，所以需要设置环境变量时，需要隐藏输入内容同时控制变量作用域在shell内部； 最终脚本如下，关键语句是export和unset； 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash# 获取当前脚本所在目录的绝对路径SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;$0&quot;)&quot; &amp;&amp; pwd)&quot;# 进入脚本所在目录cd &quot;$SCRIPT_DIR&quot;# 提示用户输入 JASYPT_ENCRYPTOR_PASSWORD，并隐藏输入内容read -sp &quot;Enter App password: &quot; JASYPT_PASSWORDechoexport JASYPT_ENCRYPTOR_PASSWORD=$JASYPT_PASSWORD# 检查是否输入了 JASYPT_ENCRYPTOR_PASSWORDif [ -z &quot;$JASYPT_PASSWORD&quot; ]; then echo &quot;jasypt.encryptor.password is required.&quot; exit 1fi# 启动Java程序并使用nohup确保它在后台运行nohup java -jar $(ls -t trade-monitor-*.jar | head -1) \\ --spring.config.location=file:./config/ \\ --spring.application.name=gateio\\ -XX:+PrintGCDetails \\ -XX:+PrintGCDateStamps \\ -Xloggc:$SCRIPT_DIR/gc.log \\ -Xmx16G \\ -Xms8G \\ -XX:+UseG1GC \\ -XX:NewRatio=3 \\ -XX:SurvivorRatio=8 \\ -XX:MaxMetaspaceSize=1024M \\ -XX:MaxGCPauseMillis=200 \\ -Xss1M &gt;/dev/null 2&gt;&amp;1 &amp;# 清除环境变量unset JASYPT_ENCRYPTOR_PASSWORD","link":"/2024/07/13/carry_coin_jasypt/"},{"title":"使用 Python 脚本清理 Carry-Coin 程序中的 Logback 日志","text":"随着监控的币种越来越多，我的 Carry-Coin 程序中日志数据的日质量也不断增加，每天的日志文件大小达到约 40G。这不仅占用了大量的存储空间，还给日志分析带来了挑战。为了更有效地管理这些日志，我已经编写了一个程序来提取日志中与交易相关的信息，供后续分析使用。 然而，在配置 Logback 的 logback-spring.xml 文件时，我设置了 appender.rollingPolicy.maxHistory 字段，旨在只保留最近 2 天的日志。然而，这一配置并未如预期生效。因此，我决定暂时使用 Python 脚本来手动清理旧的日志文件。 问题背景在 Carry-Coin 程序中，随着对越来越多币种的监控，日志文件的大小急剧增加，导致每天产生的日志文件约为 40G。虽然我已编写程序提取交易信息，但大量的日志数据依然占用了过多的磁盘空间。为此，我尝试通过调整 Logback 的配置来限制保留的日志数量。 Logback 日志管理为了管理日志，我在 logback-spring.xml 文件中配置了以下内容： 12345678910&lt;appender name=&quot;ROLLING&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;logs/carry-coin.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs/carry-coin.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;2&lt;/maxHistory&gt; &lt;!-- 只保留最近2天的日志 --&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 尽管如此，maxHistory 的配置并未生效，因此需要寻找替代解决方案。 Python 脚本实现我编写了一个 Python 脚本来自动清理日志文件，保留最近 2 天的日志。以下是脚本的实现： 12345678910111213141516171819202122import osimport timefrom datetime import datetime, timedelta# 获取两天前的时间days_to_keep = 2cutoff_time = datetime.now() - timedelta(days=days_to_keep)# 定义日志目录log_directory = &quot;/path/to/logs&quot;# 遍历日志目录，删除修改时间在 cutoff_time 之前的 .log 文件for filename in os.listdir(log_directory): file_path = os.path.join(log_directory, filename) if os.path.isfile(file_path) and filename.endswith(&quot;.log&quot;): file_mtime = os.path.getmtime(file_path) file_mtime_dt = datetime.fromtimestamp(file_mtime) if file_mtime_dt &lt; cutoff_time: os.remove(file_path) print(f&quot;Deleted: {file_path}&quot;) 说明 脚本获取当前时间的两天前，遍历指定日志目录，删除修改时间在该时间之前的 .log 文件。 仅处理以 .log 结尾的文件，确保只删除日志文件。 设置 Cron 定时任务为了定期执行这个清理脚本，我使用 cron 设置了一个定时任务，以下是设置步骤： 打开 crontab 编辑器： 1crontab -e 添加如下定时任务，每天凌晨 1 点执行： 10 1 * * * /usr/bin/python3 /path/to/your_script.py &gt;&gt; /path/to/cron_log.log 2&gt;&amp;1 保存并退出 crontab。 总结通过使用 Python 脚本，我能够有效地管理 Carry-Coin 程序中生成的日志文件，避免了因日志文件过大导致的磁盘空间不足的问题。虽然 Logback 的配置未能如预期生效，但临时解决方案为我带来了便利。在未来的项目中，我将继续探索更好的日志管理策略，以确保程序高效运行。 参考文档 Logback 文档","link":"/2024/02/13/carry_coin_log_cleanup/"},{"title":"Carry-Coin 记服务迁移和流量优化","text":"最近Contabo服务器频繁死机，发邮件给官方反应问题，一开始嘴硬说没问题让自查，沟通2天又是截图又是各种开票，最后承认问题说技术团队排查但是不给解决时间 邮件回复 VNC过去看到 sda3硬盘一直挂不上/dev/sda3: recovering journal，猜测不是硬件存储坏了就是虚拟化平台抽风；好在重启5-8次大概能进系统一次，赶紧拷数据闪人； 目前部署架构 原来contabo的机器8u24g,32TTraffic一个月$26, 相同配置国内厂商看了一圈没有羊毛，最后选择tx，但是相同配置明显贵上天，只能调整架构先开台低配2u4g/90ssd轻量服务器,把front、server、db弄回来，worker后面再说； 程序迁移后大问题没有，每种不足就是出口流量太吃紧了，轻量应用流量包只有2T,跑了10个小时流量80多G，一天毛估估200G； 优化过程iftop大概观察下流量去向，其实心里也有数，整机对外一个是通过nginx访问的front 这是给自己看的前端,还有一个就是mysql,几个worker每秒多线程读写，这部分传输过程中流量花费巨大；资源的话cpu的使用率基本维持在50左右，内存40%左右，优化空间还是有的 jeecgboot 前端肿的不行，所以nginx gzip该压的压起来,改了后观察监控发现提升可以忽略不计。 mysql是大头，这块翻了一些优化料大部分都是持久化侧的，表压缩之类的；所以换了个思路，既然是传输过程中的损耗那么大概率是jdbc驱动的事情，这么常规的场景应该有支持； 翻了mysql-connector-j-8.0.33.jar代码发现果然有戏com.mysql.cj.protocol.a.NativeProtocol中有个字段useCompression开启后mysql的传输过程会压缩，但是默认是关闭的，可以在jdbc连接字符串后面加上useCompression=true来开启压缩； CompressedPacketSender开关打开后会使用com.mysql.cj.protocol.a.CompressedPacketSender来发送数据； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * Packet sender implementation for the compressed MySQL protocol. For compressed transmission of multi-packets, split the packets up in the same way as the * uncompressed protocol. We fit up to MAX_PACKET_SIZE bytes of split uncompressed packet, including the header, into an compressed packet. The first packet * of the multi-packet is 4 bytes of header and MAX_PACKET_SIZE - 4 bytes of the payload. The next packet must send the remaining four bytes of the payload * followed by a new header and payload. If the second split packet is also around MAX_PACKET_SIZE in length, then only MAX_PACKET_SIZE - 4 (from the * previous packet) - 4 (for the new header) can be sent. This means the payload will be limited by 8 bytes and this will continue to increase by 4 at every * iteration. * * @param packet * data bytes * @param packetLen * packet length * @param packetSequence * sequence id * @throws IOException * if i/o exception occurs */ public void send(byte[] packet, int packetLen, byte packetSequence) throws IOException { this.compressedSequenceId = packetSequence; // short-circuit send small packets without compression and return if (packetLen &lt; MIN_COMPRESS_LEN) { writeCompressedHeader(packetLen + NativeConstants.HEADER_LENGTH, this.compressedSequenceId, 0); writeUncompressedHeader(packetLen, packetSequence); this.outputStream.write(packet, 0, packetLen); this.outputStream.flush(); return; } if (packetLen + NativeConstants.HEADER_LENGTH &gt; NativeConstants.MAX_PACKET_SIZE) { this.compressedPacket = new byte[NativeConstants.MAX_PACKET_SIZE]; } else { this.compressedPacket = new byte[NativeConstants.HEADER_LENGTH + packetLen]; } PacketSplitter packetSplitter = new PacketSplitter(packetLen); int unsentPayloadLen = 0; int unsentOffset = 0; // loop over constructing and sending compressed packets while (true) { this.compressedPayloadLen = 0; if (packetSplitter.nextPacket()) { // rest of previous packet if (unsentPayloadLen &gt; 0) { addPayload(packet, unsentOffset, unsentPayloadLen); } // current packet int remaining = NativeConstants.MAX_PACKET_SIZE - unsentPayloadLen; // if remaining is 0 then we are sending a very huge packet such that are 4-byte header-size carryover from last packet accumulated to the size // of a whole packet itself. We don't handle this. Would require 4 million packet segments (64 gigs in one logical packet) int len = Math.min(remaining, NativeConstants.HEADER_LENGTH + packetSplitter.getPacketLen()); int lenNoHdr = len - NativeConstants.HEADER_LENGTH; addUncompressedHeader(packetSequence, packetSplitter.getPacketLen()); addPayload(packet, packetSplitter.getOffset(), lenNoHdr); completeCompression(); // don't send payloads with incompressible data if (this.compressedPayloadLen &gt;= len) { // combine the unsent and current packet in an uncompressed packet writeCompressedHeader(unsentPayloadLen + len, this.compressedSequenceId++, 0); this.outputStream.write(packet, unsentOffset, unsentPayloadLen); writeUncompressedHeader(lenNoHdr, packetSequence); this.outputStream.write(packet, packetSplitter.getOffset(), lenNoHdr); } else { sendCompressedPacket(len + unsentPayloadLen); } packetSequence++; unsentPayloadLen = packetSplitter.getPacketLen() - lenNoHdr; unsentOffset = packetSplitter.getOffset() + lenNoHdr; resetPacket(); } else if (unsentPayloadLen &gt; 0) { // no more packets, send remaining unsent data addPayload(packet, unsentOffset, unsentPayloadLen); completeCompression(); if (this.compressedPayloadLen &gt;= unsentPayloadLen) { writeCompressedHeader(unsentPayloadLen, this.compressedSequenceId, 0); this.outputStream.write(packet, unsentOffset, unsentPayloadLen); } else { sendCompressedPacket(unsentPayloadLen); } resetPacket(); break; } else { // nothing left to send (only happens on boundaries) break; } } this.outputStream.flush(); // release reference to (possibly large) compressed packet buffer this.compressedPacket = null; } 整体思路高效地发送数据包，无论是小包还是大包，同时通过压缩减少传输数据的大小。它通过拆分、压缩和适当的序列管理确保数据完整和顺序发送. 改了以后程序跑起来，超出预期,流量消耗少了近50%，代价是cpu提了10%左右，划算。 先跑着一个月后再看。","link":"/2024/09/02/traffic_optimization_idea/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Architecture","slug":"Architecture","link":"/tags/Architecture/"},{"name":"jasypt","slug":"jasypt","link":"/tags/jasypt/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"日志清理","slug":"日志清理","link":"/tags/%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86/"},{"name":"optimization","slug":"optimization","link":"/tags/optimization/"}],"categories":[{"name":"Carry Coin","slug":"Carry-Coin","link":"/categories/Carry-Coin/"}],"pages":[{"title":"about me","text":"姓名 Gong Wei性别 男工作经验 10years+学历 本科学校 北京航空航天大学 - 计算机科学与技术邮箱 blackjackhoho@gmail.comTelegram @blackjackhohoGithub https://github.com/konbluesky 14年的老开发,在寻找一个激情、开放、和谐的团队，与志同道合的伙伴共同创造卓越的项目。 基础技能 精通Java,超过10年的企业级Java程序开发经验,对项目中用到的框架包括但不限于（Spring Full Stack,Mybatis，Netty等）有Cover和Hack能力; 熟悉Nodejs、Python、Shell等动态语言,能够灵活运用这些脚本语言解决项目中的碎片化问题,如原型验证、数据处理、自动化脚本等； 擅长OOP&amp;OOD,有复杂系统0-1设计和1-N的重构经验； 擅长Linux下工作和DevOps实践；","link":"/about/index.html"}]}