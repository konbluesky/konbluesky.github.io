{"posts":[{"title":"关于2FA","text":"什么是 2FA？2FA（Two-Factor Authentication），即双因素认证，是一种通过两种不同类别的验证手段来提高账户安全性的身份验证方法。它通过结合两个验证因素，确保即使一个验证手段被泄露，攻击者也难以完成身份冒充。 两种验证因素的类型： 知识（Something you know） 用户知道的内容，如密码、PIN 码等。 拥有（Something you have） 用户拥有的物品，如手机、硬件令牌（Token）或动态验证码（OTP）。 生物特征（Something you are） 用户自身的特征，如指纹、虹膜、面部识别。 2FA 需要至少包含其中的两种因素。例如，“密码+动态验证码”是一种常见的 2FA 实现。为什么需要 2FA？单因素认证（如仅使用密码）容易被攻破，尤其是在以下场景： 密码泄露（如数据泄漏、弱密码）。 社会工程攻击（如钓鱼）。 重用密码导致多账户失守。 2FA 提供了额外的保护层，即使密码被窃取，攻击者仍需突破第二道验证关卡。 常见 2FA 场景 密码 + 动态验证码（OTP） 登录时输入密码后，系统会发送一次性密码（通过短信、电子邮件或认证器App）。 例如：银行账户登录时使用 Google Authenticator 动态验证码。 密码 + 硬件令牌 用户需要插入 U2F 硬件令牌（如 YubiKey）并按下按钮完成身份验证。 应用：Google 工作账户、GitHub 开发者账户。 密码 + 生物特征 登录需要输入密码并完成指纹扫描或面部识别。 应用：智能手机解锁、支付验证。 生物特征 + 动态验证码 登录时需要扫描指纹，同时输入手机接收到的验证码。 应用：某些高安全性企业系统。 OTP（One-Time Password） 定义：一种只在短时间内有效、使用一次即失效的动态密码。 特点： 临时性：每次登录或交易生成一个新密码。 安全性高：即使密码被窃取，也无法重复使用。 常用方式： 短信验证码 邮件验证码 基于 TOTP（时间型动态密码）算法的应用，如 Google Authenticator。 常见开源实现OTP 相关 Google Authenticator 基于 TOTP 和 HOTP 算法的动态密码生成工具。 提供 Android 和 iOS 应用。 PyOTP 之前写的脚本就是用的这个 用 Python 实现的 OTP 库，支持 TOTP 和 HOTP。 适用于快速集成到 Python 项目中。 FreeOTP 开源的 TOTP 和 HOTP 验证器应用。 可用于 Android 和 iOS。 2FA 相关 Keycloak 开源的身份和访问管理工具，支持 2FA。 提供多种身份验证方式，包括 OTP。 Duo Security 提供基于双因素认证的开源工具，支持硬件令牌、短信和 OTP。 Authelia 全栈的身份验证系统，支持 2FA。 适合自托管环境。","link":"/zh-CN/about_2FA/"},{"title":"Carry-Coin 架构设计 Core模块(2)","text":"Carry-Coin Core的PipelineAction，Job的设计 Action 组成部分 AbstractForwardPipeline 正向套利(cex-&gt;dex)流水线抽象类 AbstractReversePipeline 逆向套利(dex-&gt;cex)流水线抽象类 CommonCutOffForwardPipeline CommonLimitWaitForwardPipeline CommonReversePipeline 逆向套利(dex-&gt;cex)流水线抽象类默认实现 DebugReversePipeline 调试用 WithdrawAndSellPipeline Cex账户留币策略时触发：当账户留币且链上价格比交易所高时，提现-&gt;dex-&gt;卖出 DepositAndSellPipeline Dex留币策略触发：钱包中留币且交易所价格大于链上：充币-&gt;cex-&gt;卖出 OnlySwapInChainPipeline Dex留币策略触发：钱包中留币且链上价格高于Cex：卖出 SolanaReversePipeline Solana逆向套利流水线 TransactionRecordFactory Job 组成部分 异步任务，优先使用websocket取数，如cex不支持则使用rest方式，rest调用一定要实现限频策略，具体见Xchange BalanceRest200msJob 每200ms 调rest接口取余额； ChainAccountMonitor10mJob 每10分钟 监控链上账户余额； CleanBalance1mJob 每1分钟 扫描账户符合条件触发留币策略 ConsumerMiddleCoinBuyAndSellJob 三角套利时，中间币消耗情况入库，订阅的交易所购买中间币（目前BNB,SOL） FundingRecordRest200msJob 每200ms 调rest接口取充提记录监控充提状态； LoaderDataContextMonitor1sJob 最初构想用来存储下单时，当前depth,ticker,orderbook等数据，数据量太大，有条件的情况下上nosql, 就不入db了； PendingPlaceOrderJob 定时扫描未完成订单，并尝试重试 ResetSymbolConfigJob 重置套利币本配置 RiseMonitorRest10sJob SelfOrderRest100msJob","link":"/zh-CN/carry_coin_architecture_3/"},{"title":"Carry-Coin 架构设计 Core模块(1)","text":"Carry-Coin Core的Center，Decenter,protocol的设计 Core组成部分Swap基本概念 SwapEngine 套利引擎，内部独立线程，Handler执行 ，Center构建,Job注册 SwapEngine最初设计可以支持dex(n)&lt;-&gt;cex(n),目前阶段仅SingleSwapEngine 实现了dex(1，n)&lt;-&gt;cex(1)的套利动作,即一个Engine绑定1个cex和N个dex； SwapContext(标记接口) SwapContext是SwapEngine的上下文，是个巨型类，为了跨交易所共用上下文预留的,主要是保存SwapEngine运行时的数据，包含了所有重要对象的引用：交易所信息，交易对信息，交易所账户信息; SwapConfig SwapConfig是SwapEngine的配置类，主要是保存SwapEngine运行时所需的配置信息; SwapHandler 用来初始化Context，同步job的阻塞加载，异步job的注册，BizDataLoaderContext首次初始化和校验 SwapInitializerConfig 根据yml初始化SwapLauncher来触发Engine工作； SwapLauncher 交易引擎启动器 Center Cex中心交易所相关的抽象和套利动作 CenterExchangeHolder 中心交易所的顶级抽象，主要是一些技术动作： 注册同步和异步的取数器（Job），获取Context数据等动作 交易所支持同步和异步取数两种模式，同步在SwapEngine初始化时执行一次，异步周期性运行； 周期性执行使用ScheduledExecutorService，实现使用了alibaba的transmittable-thread-local库，主要目的解决异步执行时上下文传递的问题； Job方式取来的数据都会放在BizDataLoaderContext容器中； AbstractCenterExchangeHolder 对CenterExchangeHolder的基本实现 CenterExchangeHolderBehavior 业务动作抽象接口：Limit/Marker下单，撤单，获取订单状态，提现，转账等业务动作,这个接口也是pipeline和job中操作Cex的核心，非必要业务流中不操作CenterExchangeHolder,AbstractCenterExchangeHolder这种顶级接口； Cex交易所操作使用Xchange完成; FacilitySupport 提供一套基本的Cex实现模板 CenterSymbolInfo Cex侧套利相关配置信息 Decenter Dex去中心交易平台相关的抽象, Decenter.protocol Decenter中SwapProtocol协议抽象，目前已实现包含solana,bsc链，odos,zerox平台的询价、交易动作;设计过程中难点在于对不同链的交易动作进行同一视角进行抽象和设计； EVM部分 GenericWeb3jBehavior 链上动作的通用抽象，默认只实现getNetwork,getWeb3jManager,考虑到多链支持Client客户端不定，所以作为泛型传入； 必要动作queryTxConfirmed,getRawAmountOut,getBalanceOfNode做抽象方法，考虑到这几个方法不挑网络，入参回参明确，所以放在此处； 不同链差异化动作放在下层实现. EthGenericWeb3jBehavior 具象evm链的实现，主要是实现网络层面、Token层面的一些方法了allowance, getTransactionGasLimit, signTransaction, waitTxConfirmed, queryTxConfirmed, getNonce, getBalanceOfNode, tokenTransfer, getGasProvider, gasProvider GenericSwapV2Impl,GenericSwapV3Impl 基于EthGenericWeb3jBehavior完成Dex swap全过程的方法,包含：getAmountsOut,swapExactTokensForTokens，swapExactTokensForTokensSupportingFeeOnTransferTokens getRawAmountOut区别于getAmountsOut，是用来通过evm中log数据获取最终交换到的token数量； SwapExactTForTParam 上层通过该类传入swap所需参数； Solana部分ODOS部分Strategy 交易策略 swap 套利动作","link":"/zh-CN/carry_coin_architecture_2/"},{"title":"使用 Python 脚本清理 Carry-Coin 程序中的 Logback 日志","text":"随着监控的币种越来越多，我的 Carry-Coin 程序中日志数据的日质量也不断增加，每天的日志文件大小达到约 40G。这不仅占用了大量的存储空间，还给日志分析带来了挑战。为了更有效地管理这些日志，我已经编写了一个程序来提取日志中与交易相关的信息，供后续分析使用。 然而，在配置 Logback 的 logback-spring.xml 文件时，我设置了 appender.rollingPolicy.maxHistory 字段，旨在只保留最近 2 天的日志。然而，这一配置并未如预期生效。因此，我决定暂时使用 Python 脚本来手动清理旧的日志文件。 问题背景在 Carry-Coin 程序中，随着对越来越多币种的监控，日志文件的大小急剧增加，导致每天产生的日志文件约为 40G。虽然我已编写程序提取交易信息，但大量的日志数据依然占用了过多的磁盘空间。为此，我尝试通过调整 Logback 的配置来限制保留的日志数量。 Logback 日志管理为了管理日志，我在 logback-spring.xml 文件中配置了以下内容： 12345678910&lt;appender name=&quot;ROLLING&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;logs/carry-coin.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs/carry-coin.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;2&lt;/maxHistory&gt; &lt;!-- 只保留最近2天的日志 --&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 尽管如此，maxHistory 的配置并未生效，因此需要寻找替代解决方案。 Python 脚本实现我编写了一个 Python 脚本来自动清理日志文件，保留最近 2 天的日志。以下是脚本的实现： 12345678910111213141516171819202122import osimport timefrom datetime import datetime, timedelta# 获取两天前的时间days_to_keep = 2cutoff_time = datetime.now() - timedelta(days=days_to_keep)# 定义日志目录log_directory = &quot;/path/to/logs&quot;# 遍历日志目录，删除修改时间在 cutoff_time 之前的 .log 文件for filename in os.listdir(log_directory): file_path = os.path.join(log_directory, filename) if os.path.isfile(file_path) and filename.endswith(&quot;.log&quot;): file_mtime = os.path.getmtime(file_path) file_mtime_dt = datetime.fromtimestamp(file_mtime) if file_mtime_dt &lt; cutoff_time: os.remove(file_path) print(f&quot;Deleted: {file_path}&quot;) 说明 脚本获取当前时间的两天前，遍历指定日志目录，删除修改时间在该时间之前的 .log 文件。 仅处理以 .log 结尾的文件，确保只删除日志文件。 设置 Cron 定时任务为了定期执行这个清理脚本，我使用 cron 设置了一个定时任务，以下是设置步骤： 打开 crontab 编辑器： 1crontab -e 添加如下定时任务，每天凌晨 1 点执行： 10 1 * * * /usr/bin/python3 /path/to/your_script.py &gt;&gt; /path/to/cron_log.log 2&gt;&amp;1 保存并退出 crontab。 总结通过使用 Python 脚本，我能够有效地管理 Carry-Coin 程序中生成的日志文件，避免了因日志文件过大导致的磁盘空间不足的问题。虽然 Logback 的配置未能如预期生效，但临时解决方案为我带来了便利。在未来的项目中，我将继续探索更好的日志管理策略，以确保程序高效运行。 参考文档 Logback 文档","link":"/zh-CN/carry_coin_log_cleanup/"},{"title":"Carry-Coin 架构设计 SymbolLedger (4)","text":"Carry-Coin 套利币本 SymbolLedger 设计，SymbolLedger负责存放套利过程中交易对信息，其中包括symbol在Cex中的各项配置、套利阈值等，Dex中的各种合约信息、阈值、交易参数等 SymbolLedger一个交易所对应一个SymbolLedger实例,程序启动后通过json配置文件进行加载； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * &lt;pre&gt; * 此类用来存储市面上所有的交易对信息 * 维护方式: 基础信息手工,其他信息通过程序自动获取; * 更新周期: 定期更新; * 作用: 以此账簿上的币作为循化基础,再从各交易所拉取对应信息; * &lt;/pre&gt; * &lt;p&gt; @Date : 2023/3/21 &lt;/p&gt; * &lt;p&gt; @Project : block-farming&lt;/p&gt; * * &lt;p&gt; @author konbluesky &lt;/p&gt; */@Slf4j@Datapublic class SymbolLedger { /** * 如是内存模式则不进行数据库持久化 */ private boolean memoryMode = false; /** * 更新symbolPairConfigs时,一定要重新对symbolPairConfigMap和symbolPairConfigMap_symbolKey进行更新 * 否则getSymbolPairConfig会失效 * @param symbolPairConfigs */ public void setSymbolPairConfigs(List&lt;SymbolPairConfig&gt; symbolPairConfigs) { this.symbolPairConfigs = symbolPairConfigs; for(SymbolPairConfig symbolPairConfig : symbolPairConfigs){ updateSymbolPairConfig(symbolPairConfig); } log.info(&quot;SymbolLedger更新symbolPairConfigs&quot;); } private List&lt;SymbolPairConfig&gt; symbolPairConfigs = Lists.newCopyOnWriteArrayList(); private Map&lt;String, SymbolPairConfig&gt; symbolPairConfigMap = Maps.newConcurrentMap(); private Map&lt;String, SymbolPairConfig&gt; symbolPairConfigMap_symbolKey = Maps.newConcurrentMap(); // private Table&lt;String, String, SymbolPairConfig&gt; symbolPairConfigMap = Tables.synchronizedTable(HashBasedTable.create()); public void put(SymbolPairConfig symbolPairConfig) { symbolPairConfigs.add(symbolPairConfig); updateSymbolPairConfig(symbolPairConfig); } private void updateSymbolPairConfig(SymbolPairConfig symbolPairConfig){ CenterSymbolInfo centerSymbolInfo = symbolPairConfig.getCenterSymbolInfo(); symbolPairConfigMap.put(centerSymbolInfo.getBaseCurrency() .toLowerCase(), symbolPairConfig); symbolPairConfigMap_symbolKey.put(centerSymbolInfo.getBaseCurrency() .toLowerCase() + &quot;/&quot; + centerSymbolInfo.getQuoteCurrency() .toLowerCase(), symbolPairConfig); } @Deprecated public SymbolPairConfig getSymbolPairConfig(String baseCurrency) { return symbolPairConfigMap.get(baseCurrency.toLowerCase()); } public List&lt;SymbolPairConfig&gt; getSymbolPairConfigsBy(String baseCurrency) { List&lt;SymbolPairConfig&gt; result = Lists.newArrayList(); symbolPairConfigMap_symbolKey.forEach((k, v) -&gt; { if(k.toLowerCase().startsWith(baseCurrency.toLowerCase())) { result.add(v); } }); return result; } public SymbolPairConfig getSymbolPairConfig(String baseCurrency, String quoteCurrency) { return symbolPairConfigMap_symbolKey.get(baseCurrency.toLowerCase() + &quot;/&quot; + quoteCurrency.toLowerCase()); }} SymbolLedger构建的静态工厂,json配置通过carry-config-generator(python)生成 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249/** * &lt;pre&gt; * 1. 交易对配置文件工厂,目前实现从HUOBI.txt文件中读取; * 2. 可以在jar包所在目录下创建config目录,将配置文件放入config目录下,程序会自动读取; * &lt;/pre&gt; */@Slf4jpublic class SymbolLedgerFactory { public static final String SYMBOL_HUOBI_BOOKS_FILE = &quot;HUOBI.txt&quot;; public static final String SYMBOL_XT_BOOKS_FILE = &quot;XT.txt&quot;; public static final String SYMBOL_BINANCE_BOOKS_FILE = &quot;BIAN.txt&quot;; public static final String SYMBOL_MEXC_BOOKS_FILE = &quot;MXCAll.txt&quot;; public static final String SYMBOL_GATEIO_BOOKS_FILE = &quot;GATEIO.txt&quot;; public static final String SYMBOL_KUCOIN_BOOKS_FILE = &quot;KUCOIN.txt&quot;; /** * TODO 从文件中读取交易对配置,目前只解析部分字段;有需要实时更新的字段到时候从服务器上实时拉取; * swapStableCoinContractAdd 字段配置决定了与交易所的对的匹配; * * @param symbolBooksFile * @param swapConfig * @return */ private static SymbolLedger create(String symbolBooksFile, SwapConfig swapConfig) { Preconditions.checkArgument(swapConfig != null); JSONArray jsonArray = getJsonArrayByFile(symbolBooksFile); SymbolLedger symbolLedger = new SymbolLedger(); for (int i = 0; i &lt; jsonArray.size(); i++) { JSONObject item = jsonArray.getJSONObject(i); // continue to parse the json object if (Strings.isNullOrEmpty(item.getString(&quot;swapContract&quot;)) || item.getString(&quot;swapStableCoinContract&quot;) .equalsIgnoreCase(&quot;cake&quot;)) { continue; } SymbolPairConfig symbolPairConfig = new SymbolPairConfig(); symbolPairConfig.setBaseCurrency(item.getString(&quot;swapCoinContract&quot;)); int chainId = item.getInteger(&quot;chainId&quot;) != null ? item.getInteger(&quot;chainId&quot;) : NetworkEnum.BSC.getChainId(); String stableName = SymbolTokenHelper.getTokenInfoByAddressReturnSymbol(chainId, item.getString(&quot;swapStableCoinContractAdd&quot;)); symbolPairConfig.setQuoteCurrency(Currency.USDT.getCurrencyCode()); // symbolPairConfig.setSymbol(symbolPairConfig.getBaseCurrency() + &quot;/&quot; + symbolPairConfig.getQuoteCurrency()); // 链上交易对和cex交易对 分别存储,交易所对,目前统一使用usdt CenterSymbolInfo centerSymbolInfo = new CenterSymbolInfo(); centerSymbolInfo.setBaseCurrency(symbolPairConfig.getBaseCurrency()); centerSymbolInfo.setQuoteCurrency(Currency.USDT.getCurrencyCode()); centerSymbolInfo.setCexMaxOrderForUSDT(item.getBigDecimal(&quot;maxOrderForUsdt&quot;) == null ? swapConfig.getGlobalMaxOrderForUsdt() : item.getBigDecimal(&quot;maxOrderForUsdt&quot;)); centerSymbolInfo.setCexMinOrderForUSDT(item.getBigDecimal(&quot;minOrderForUsdt&quot;) == null ? swapConfig.getGlobalMinOrderForUsdt() : item.getBigDecimal(&quot;minOrderForUsdt&quot;)); centerSymbolInfo.getAskPosition() .set(item.getInteger(&quot;askPosition&quot;) == null || item.getInteger(&quot;askPosition&quot;) == 0 ? 3 : item.getInteger(&quot;askPosition&quot;)); symbolPairConfig.setCenterSymbolInfo(centerSymbolInfo); // 设置去中心化交易所配置信息; DecenterSymbolInfo decenterSymbolInfo = new DecenterSymbolInfo(); decenterSymbolInfo.setBaseCurrency(symbolPairConfig.getBaseCurrency()) .setQuoteCurrency(stableName == null ? CoinEnum.getCoin(item.getString(&quot;swapStableCoinContractAdd&quot;)) .name() : stableName) .setMiddleCurrency(item.getString(&quot;swapMiddleCoinContract&quot;)) .setDexName(item.getString(&quot;dex_name&quot;)) .setDexProtocolVersion(item.getString(&quot;liquidity_type&quot;)) // 链id .setChainIds(Set.of(chainId)) .setStableCoinContractAddress(item.getString(&quot;swapStableCoinContractAdd&quot;)) .setMiddleCoinContractAddress(item.getString(&quot;swapMiddleCoinContractAdd&quot;)) .setTradeCoinContractAddress(item.getString(&quot;swapCoinContractAdd&quot;)) .setSwapContractAddress(item.getString(&quot;swapContract&quot;)) .setBurnFee(item.getBigDecimal(&quot;burn&quot;)) .setBuyTax(item.getBigDecimal(&quot;buyTax&quot;))// 买入税率 .setSellTax(item.getBigDecimal(&quot;sellTax&quot;))//卖出税率 // .setSellTax(item.getBigDecimal(&quot;burn&quot;))// 卖出税率， 老的配置文件中就是sellTax .setDexBuySlipPoint(item.getBigDecimal(&quot;dexSlipPoint&quot;) .add(swapConfig.getGlobalDexSlipPoint())) .setStableCoinDecimals(item.getIntValue(&quot;stableCoinDecimals&quot;)) .setTradeCoinDecimals(item.getIntValue(&quot;coinDecimals&quot;)) .setMiddleCoinDecimals(item.getIntValue(&quot;middleCoinDecimals&quot;)) .setMethod(item.getString(&quot;method&quot;)) .setBuyPosition(item.getIntValue(&quot;currentDepthPosition&quot;)) .setReplyPro(item.getBigDecimal(&quot;replyPro&quot;)) // 反向利润放大的比例 .setDepthPro(item.getBigDecimal(&quot;depthPro&quot;)) // 反向深度缩小的比例 .setV3LoopContractAddress(item.getString(&quot;lpAdd&quot;)) // v3 的loopAddress .setV3Fee(item.getString(&quot;feev3&quot;)) // v3 的fee .setDexMaxOrderForUSDT(item.getBigDecimal(&quot;dexMax&quot;) == null ? swapConfig.getGlobalMaxOrderForUsdt() : item.getBigDecimal(&quot;dexMax&quot;)) // 反向最大下单量 .setDexMinOrderForUSDT(item.getBigDecimal(&quot;dexMin&quot;) == null ? swapConfig.getGlobalMinOrderForUsdt() : item.getBigDecimal(&quot;dexMin&quot;));// 反向最小下单量 decenterSymbolInfo.setExtensionDexHandlerConfig(new ExtensionDexHandlerConfig(item)); decenterSymbolInfo.init(); symbolPairConfig.setDecenterSymbolInfo(decenterSymbolInfo); symbolPairConfig.set_rawJson(item); symbolLedger.put(symbolPairConfig); } return symbolLedger; } private static JSONArray getJsonArrayByFile(String symbolHuobiBooksFile) { File configFile = PathUtil.stairsLoad(symbolHuobiBooksFile, &quot;config&quot;); try { if (configFile == null) { log.warn(&quot;Not fount SymbolBook config file.{}&quot;, symbolHuobiBooksFile); String tempPath = System.getProperty(&quot;java.io.tmpdir&quot;) + System.currentTimeMillis(); String tempFile = Paths.get(tempPath, File.separator, symbolHuobiBooksFile) .toString(); Resource resource = new ClassPathResource(symbolHuobiBooksFile); InputStream initialStream = resource.getInputStream(); byte[] buffer = new byte[initialStream.available()]; initialStream.read(buffer); configFile = new File(tempFile); configFile.getParentFile() .mkdirs(); Files.write(buffer, configFile); log.info(&quot;Loading default SymbolBook config file from classpath: {} &quot;, resource.getURL()); } String jsonContext = Joiner.on(&quot;&quot;) .join(Files.readLines(configFile, Charsets.UTF_8)); if (JSON.isValidArray(jsonContext)) { return JSON.parseObject(jsonContext, JSONArray.class); } } catch (Exception e) { log.error(e.getMessage(), e); throw new SwapException(&quot;SymbolBook config loading failed.&quot;); } return new JSONArray(); } public static SymbolLedger createXT(SwapConfig swapConfig) { return create(SYMBOL_XT_BOOKS_FILE, swapConfig); } public static SymbolLedger createHuoBi() { return create(SYMBOL_HUOBI_BOOKS_FILE, new SwapConfig()); } public static SymbolLedger createGateio() { return create(SYMBOL_GATEIO_BOOKS_FILE, new SwapConfig()); } public static SymbolLedger createGateio(SwapConfig swapConfig) { return create(SYMBOL_GATEIO_BOOKS_FILE, swapConfig); } public static SymbolLedger createKucoin(SwapConfig swapConfig) { return create(SYMBOL_KUCOIN_BOOKS_FILE, swapConfig); } public static SymbolLedger createOKex() { return create(SYMBOL_HUOBI_BOOKS_FILE, new SwapConfig()); } public static SymbolLedger createOKex(SwapConfig swapConfig) { return create(SYMBOL_HUOBI_BOOKS_FILE, swapConfig); } public static SymbolLedger createHuoBi(SwapConfig swapConfig) { return create(SYMBOL_HUOBI_BOOKS_FILE, swapConfig); } public static SymbolLedger createBinance(SwapConfig swapConfig) { return create(SYMBOL_BINANCE_BOOKS_FILE, swapConfig); } public static SymbolLedger createMEXC(SwapConfig swapConfig) { return create(SYMBOL_MEXC_BOOKS_FILE, swapConfig); } /** * 将配置文件内容刷入db * 外部通过SwapControlHolder 来对状态进行控制和判断 * * @param symbolLedger * @param exchangeType * @param isMonitor 开关用来控制swapSymbolPairConfigRecord 记录默认是监听状态还是， 非监听状态， * 首次程序启动的时候是非监听的，需要web端显式的开启，后续job中动态调整默认都是监听状态的 */ public static void flushToDb(SymbolLedger symbolLedger, ExchangeType exchangeType, boolean isMonitor) { if (symbolLedger.isMemoryMode()) { return; } SwapSymbolPairConfigRecordRepository res = SpringUtil.getBean(SwapSymbolPairConfigRecordRepository.class); res.deleteAllByExchangeType(exchangeType); res.flush(); List&lt;SwapSymbolPairConfigRecord&gt; all = Lists.newArrayList(); symbolLedger.getSymbolPairConfigs().forEach(symbolPairConfig -&gt; { SwapSymbolPairConfigRecord swapSymbolPairConfigRecord = null; if (isMonitor) { swapSymbolPairConfigRecord = SwapSymbolPairConfigRecord.createLoadMonitor(symbolPairConfig, exchangeType); SwapControlManager.putItem(exchangeType, symbolPairConfig.getUniDexIdentify(), swapSymbolPairConfigRecord); } else { swapSymbolPairConfigRecord = SwapSymbolPairConfigRecord.createUnMonitor(symbolPairConfig, exchangeType); SwapControlManager.putItem(exchangeType, symbolPairConfig.getUniDexIdentify(), swapSymbolPairConfigRecord); } all.add(swapSymbolPairConfigRecord); }); res.saveAllAndFlush(all); log.info(&quot;Load config from config file, Flush to db is ok ! Record size is :{} &quot;, all.size()); } /** * 增量更新配置文件 * 1. 数据库中载入当前交易所币配置 * 2. 从内存中获取当前交易所币配置 * 3. 比较数据库中不在内存的配置，更新状态 * 4. 将关闭的币种组装日志打印出来 */ public static void incrementalUpdate(SymbolLedger symbolLedger, ExchangeType exchangeType) { if (symbolLedger.isMemoryMode()) { return; } SwapSymbolPairConfigRecordRepository res = SpringUtil.getBean(SwapSymbolPairConfigRecordRepository.class); List&lt;SwapSymbolPairConfigRecord&gt; all = res.findAllByExchangeType(exchangeType); String changeCurrency = &quot;&quot;; int closeCount = 0; for (SwapSymbolPairConfigRecord swapSymbolPairConfigRecord : all) { String symbol = swapSymbolPairConfigRecord.getSymbol(); if (symbolLedger.getSymbolPairConfig(symbol.split(&quot;/&quot;)[0], symbol.split(&quot;/&quot;)[1]) == null) { swapSymbolPairConfigRecord.setMonitorStatus(SwapSymbolPairConfigRecord.MonitorStatus.UNMONITOR); changeCurrency += symbol + &quot;,&quot;; closeCount++; } } res.saveAllAndFlush(all); String msg = Utils.format(&quot;{} 交易所内存币本配置已过滤,总数:{} 关闭数量:{} 关闭币种:{}&quot;, exchangeType, all.size(), closeCount, changeCurrency); log.info(msg); SwapMessageSender.sendMessage(exchangeType, msg); log.info(&quot;Incremental update config from config file, Flush to db is ok ! Record size is :{} &quot;, all.size()); } SymbolPairConfig 类, 用来存储某个交易对(ABC/USDT)的配置信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * &lt;p&gt; @Date : 2023/3/21 &lt;/p&gt; * &lt;p&gt; @Project : block-farming&lt;/p&gt; * * &lt;p&gt; @author konbluesky &lt;/p&gt; */@Datapublic class SymbolPairConfig { //TODO 现阶段 symbolInfo 是1-1关系 /** * 交易对在中心化交易所的信息 */ private CenterSymbolInfo centerSymbolInfo; /** * 交易对在去中心化交易所的信息 */ private DecenterSymbolInfo decenterSymbolInfo; /** * 交易对显示名称 BTC/USDT */ public String getSymbol() { return baseCurrency+&quot;/&quot;+quoteCurrency; } /** * RITE/USDT-RITE/USDT-PancakeV2-UniV2 * @return */ public String getUniDexIdentify(){ return centerSymbolInfo.getSymbol() + &quot;-&quot; + decenterSymbolInfo.getSymbol() + &quot;-&quot; + decenterSymbolInfo.getDexName() + &quot;-&quot; + decenterSymbolInfo.getDexProtocolVersion(); } /** * 交易对基础货币 BTC */ private String baseCurrency; /** * 交易对报价货币 USDT */ private String quoteCurrency; /** * 允许开启的实例数 */ private AtomicInteger reverseAllowInstanceNum = new AtomicInteger(1); private AtomicInteger forwardAllowInstanceNum = new AtomicInteger(1); /** * 开启翻倍后，设置x分钟激情时间，进行翻倍 */ private AtomicLong reversePassionTime = new AtomicLong(0); private AtomicLong forwardPassionTime = new AtomicLong(0); /** * 交易对的利润阈值,一般在交易所holder初始化的时候从SwapConfig获取; * TODO 这里的阈值可基于全局的做覆盖; */ private BigDecimal profitThreshold; private BigDecimal profitThresholdRate; private BigDecimal _origin_profitThresholdRate; private JSONObject _rawJson; public void setProfitThresholdRate(BigDecimal profitThresholdRate) { this.profitThresholdRate = profitThresholdRate; this._origin_profitThresholdRate = profitThresholdRate; } public void setProfitThresholdRateDouble() { profitThresholdRate = profitThresholdRate.multiply(new BigDecimal(&quot;1.3&quot;)); } public void resetProfitThresholdRate() { profitThresholdRate = _origin_profitThresholdRate; } /** * 提现次数自增一次 * Increase WithdrawTime */ public void increaseWithdrawTimes() { centerSymbolInfo.getLastWithdrawTime().set(System.currentTimeMillis()); centerSymbolInfo.increaseWithdrawTimes(); } public boolean isMiddleCoin() { return !Strings.isNullOrEmpty(decenterSymbolInfo.getMiddleCoinContractAddress()); } public String getSymbolNoOblique() { return getSymbol().replace(&quot;/&quot;, &quot;&quot;); }} CenterSymbolInfo 类, 用来存储某个交易对(ABC/USDT)的Cex配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * * &lt;p&gt; @Date : 2023/3/20 &lt;/p&gt; * &lt;p&gt; @Project : block-farming&lt;/p&gt; * * &lt;p&gt; @author konbluesky &lt;/p&gt; */@Data@Slf4jpublic class CenterSymbolInfo { public String getSymbol() { return baseCurrency + &quot;/&quot; + quoteCurrency; } /** * 注意这里是[交易所]对应的基础货币 BTC */ private String baseCurrency; /** * 注意这里是[交易所]对应的交易对报价货币 USDT */ private String quoteCurrency; private Double price; /** * 交易所体现时一般需要指定链名或者网络名 */ private String chainName; /** * 提现次数 */ private AtomicInteger withdrawTimes = new AtomicInteger(0); /** * 最小提现手续费 */ private BigDecimal withdrawMinFee = BigDecimal.ZERO; /** * 手续费换算成美元 */ private BigDecimal withdrawMinFee$ = BigDecimal.ZERO; /** * 传入实时的单价，计算出手续费绝对刀 * @param unitPrice */ public void setWithdrawMinFee$(BigDecimal unitPrice) { this.withdrawMinFee$ = Utils.getScale(unitPrice.multiply(withdrawMinFee)); } /** * 最后一次的提现时间 */ private AtomicLong lastWithdrawTime = new AtomicLong(System.currentTimeMillis()); /** * 最后一次下卖单时间 */ private AtomicLong lastPlaceSellOrderTime = new AtomicLong(System.currentTimeMillis()); private AtomicLong lastPlaceBuyOrderTime = new AtomicLong(System.currentTimeMillis()); /** * 卖单默认位置,此位置是口语中的卖一卖二，不是数组下标 */ private AtomicInteger askPosition = new AtomicInteger(0); /** * 挂单检查时间(卖单) */ private int askOrderWaitSeconds = 5; /** * 交易所固定最大下单金额(usdt为单位) */ private BigDecimal CexMaxOrderForUSDT; /** * 交易所固定最小下单金额(usdt为单位) */ private BigDecimal CexMinOrderForUSDT; /** * 留币时保存的卖出下单ID; * remain 留存 sell 出售 orderId 订单ID */ private String remainSellOrderId; /** * 提现次数自增一次 */ public void increaseWithdrawTimes() { withdrawTimes.set(withdrawTimes.get() + 1); }} DecenterSymbolInfo 类, 用来存储某个交易对(ABC/USDT)的Dex配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245/** * &lt;p&gt; @Date : 2023/3/20 &lt;/p&gt; * &lt;p&gt; @Project : block-farming&lt;/p&gt; * * &lt;p&gt; @author konbluesky &lt;/p&gt; */@Accessors(chain = true)@Data@Slf4jpublic class DecenterSymbolInfo { private String dexName; private String dexProtocolVersion; public String getSymbol() { if(Strings.isNullOrEmpty(middleCoinContractAddress)) { return baseCurrency + &quot;/&quot; + quoteCurrency; }else{ return baseCurrency + &quot;/&quot; + middleCurrency + &quot;/&quot; + quoteCurrency; } } /** * 注意这里是[链上]对应的基础货币 BTC */ private String baseCurrency; /** * 注意这里是[链上]对应的交易对报价货币 USDT */ private String quoteCurrency; /** * 注意这里是[链上]对应的交易对中间报价货币 */ private String middleCurrency; private Set&lt;Integer&gt; chainIds; /** * TODO 未来需要支持一个币种在多个链上的支持, 目前只考虑币种只在一个链上活跃 * @return */ public Integer getFirstChainId(){ return chainIds.iterator().next(); } /**************************************************************************************************/ /************************************** 链上的地址配置信息 *******************************************/ /**************************************************************************************************/ /** * 为了方便存取,围绕token,将常用的信息包装起来 */ private CurrencyBag stable; private CurrencyBag trade; private CurrencyBag middle; public void init() { if (stable == null) { stable = CurrencyBag.of(stableCoinContractAddress, quoteCurrency, getStableCoinDecimals()); } if (trade == null) { trade = CurrencyBag.of(tradeCoinContractAddress, baseCurrency, getTradeCoinDecimals()); } if (middle == null) { middle = CurrencyBag.of(middleCoinContractAddress, middleCurrency, getMiddleCoinDecimals()); } } /** * 稳定币的合约地址 * USTD,ETH,BTC 等 */ private String stableCoinContractAddress; /** * 中间币的合约地址 * BNB 有自己独立的链的等 */ private String middleCoinContractAddress; /** * 交易币的合约地址 * 即最终操作的目标币地址 * 原代码中的:swapCoinContractAdd */ private String tradeCoinContractAddress; /** * v3流通性的合约地址 */ private String v3LoopContractAddress; /** * v3手续费的 */ private String v3Fee; /** * 去中心化交易所的合约地址 */ private String swapContractAddress; /** * 反向套利，从蛋糕到交易所，稳定币额度 * bnb对就进行交易所价格查询，转换成对应的bnb * &lt;pre&gt; * 声明 BidDepths,bidOnePrice,BidDepthsAllAmount; * swapStableCoinNumOut = bidOnePrice * BidDepthsAllAmount; * &lt;/pre&gt; */ private AtomicDouble swapStableCoinNumOut; /** * 非稳定币的兑换数量,个数 */ private AtomicDouble swapFStableCoinNum; /** * 稳定币的兑换数量,个数 */ private AtomicDouble swapStableCoinNum; /** * 价格精度 最小就是0.0001 */ private String priceDecimals; /** * 数量精度 最小就是0.01 */ private String numDecimals; /** * 卖时燃烧的手续费 */ private BigDecimal burnFee; /** * 其他费用，初步用来保存转移费用，有些币种的转移费用 */ private BigDecimal otherFee = BigDecimal.ZERO; /** * 链上买币滑点 */ private BigDecimal dexBuySlipPoint; private BigDecimal _origin_dexBuySlipPoint; /** * 买时 税率 */ private BigDecimal buyTax = BigDecimal.ZERO; /** * 卖时 税率 */ private BigDecimal sellTax = BigDecimal.ZERO; /** * 交易币的精度,在程序启动时通过TokenClient从链上合约中查询 */ private int tradeCoinDecimals = 0; /** * 稳定币的精度,在程序启动时通过TokenClient从链上合约中查询 */ private int stableCoinDecimals = 0; /** * 中间币的精度,在程序启动时通过TokenClient从链上合约中查询 */ private int middleCoinDecimals = 0; /** * 链上固定最大下单金额(usdt为单位) */ private BigDecimal dexMaxOrderForUSDT; /** * 链上固定最小下单金额(usdt为单位) */ private BigDecimal dexMinOrderForUSDT; /** * dex购买状态，用于判断是否蛋糕买了，然后回交易所 * 对于这种情况，要进行停止蛋糕购买及交易所到蛋糕的业务 * 根据交易所充值到账时间 一般需要2分钟，即120秒，那130秒内都必须把价格降 */ private AtomicLong dexBuyTimestamp = new AtomicLong(0); private String method; /** * 反向套利时，需要监控买盘的数据， 这是买盘的位置 * 对应的是centerSymbolInfo的askPosition */ private int buyPosition; /** * 反向套利时，深度需要*depthPro ，进行打折 */ private BigDecimal depthPro; public DecenterSymbolInfo setDexBuySlipPoint(BigDecimal dexBuySlipPoint) { this.dexBuySlipPoint = dexBuySlipPoint; // 保留原始值用于恢复 this._origin_dexBuySlipPoint = dexBuySlipPoint; return this; } private ExtensionDexHandlerConfig extensionDexHandlerConfig; /** * 反向套利时的放大比例 */ private BigDecimal replyPro; public boolean isV3(){ return getDexProtocolVersion().toLowerCase().contains(&quot;v3&quot;.toLowerCase()); } public boolean isV2(){ return getDexProtocolVersion().toLowerCase().contains(&quot;v2&quot;.toLowerCase()); } /** * 对dexBuySlipPoint滑点1.5倍； */ public void setDexBuySlipPointDouble() { dexBuySlipPoint = dexBuySlipPoint.multiply(replyPro); } public void resetDexBuySlipPoint() { dexBuySlipPoint = _origin_dexBuySlipPoint; }}","link":"/zh-CN/carry_coin_architecture_4/"},{"title":"Carry-Coin 中 Jasypt 的应用","text":"自从最近L君小弟电脑中毒，疑似私钥泄漏，导致3W u被盗，反观我的程序一直以来裸奔的状态下，再次菊花一紧。于是，我开始了对Spring Boot的jasypt加密配置的研究。 最坏情况服务器即使被黑，也要尽可能保证程序的安全。 配置文件中关键信息： 交易所token，钱包私钥加密； jar中yml打包时排除，服务器上用密文配置执行； 解密密码动态设置； jasypt 集成程序引入pom.xml 12345 &lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt;&lt;/dependency&gt; application.yml 123jasypt: encryptor: password: ${JASYPT_ENCRYPTOR_PASSWORD} Application.java 12345678910111213141516171819202122/** * &lt;p&gt; @Date : 2023/3/19 &lt;/p&gt; * &lt;p&gt; @author konbluesky &lt;/p&gt; */@SpringBootApplication(scanBasePackages = &quot;com.block&quot;)@EnableScheduling@EnableAsync@EnableJpaAuditing// WARN bad smell@EncryptablePropertySources({ @EncryptablePropertySource(value = &quot;file:./config/application.yml&quot;,ignoreResourceNotFound = true), @EncryptablePropertySource(value = &quot;classpath:application.yml&quot;,ignoreResourceNotFound = true)})@EnableEncryptablePropertiespublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 打包排除pom.xml,设置打包时排除yml文件，避免铭文yml误打包到jar中 123456789101112 &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;!-- 用springboot 打包时 排除yml--&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt;&lt;/resources&gt; 启动脚本原启动方式需要通过-Djasypt.encryptor.password=”the password”,来设置加密密码。这种方式用jps -mlv可以看到启动命令，但是这种方式不安全，依然容易泄露密码。为了安全起见，我们需要在启动脚本中设置环境变量 JASYPT_ENCRYPTOR_PASSWORD 来加密配置文件中的敏感信息。设置后又担心环境变量被echo出来，所以需要设置环境变量时，需要隐藏输入内容同时控制变量作用域在shell内部； 最终脚本如下，关键语句是export和unset； 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash# 获取当前脚本所在目录的绝对路径SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;$0&quot;)&quot; &amp;&amp; pwd)&quot;# 进入脚本所在目录cd &quot;$SCRIPT_DIR&quot;# 提示用户输入 JASYPT_ENCRYPTOR_PASSWORD，并隐藏输入内容read -sp &quot;Enter App password: &quot; JASYPT_PASSWORDechoexport JASYPT_ENCRYPTOR_PASSWORD=$JASYPT_PASSWORD# 检查是否输入了 JASYPT_ENCRYPTOR_PASSWORDif [ -z &quot;$JASYPT_PASSWORD&quot; ]; then echo &quot;jasypt.encryptor.password is required.&quot; exit 1fi# 启动Java程序并使用nohup确保它在后台运行nohup java -jar $(ls -t trade-monitor-*.jar | head -1) \\ --spring.config.location=file:./config/ \\ --spring.application.name=gateio\\ -XX:+PrintGCDetails \\ -XX:+PrintGCDateStamps \\ -Xloggc:$SCRIPT_DIR/gc.log \\ -Xmx16G \\ -Xms8G \\ -XX:+UseG1GC \\ -XX:NewRatio=3 \\ -XX:SurvivorRatio=8 \\ -XX:MaxMetaspaceSize=1024M \\ -XX:MaxGCPauseMillis=200 \\ -Xss1M &gt;/dev/null 2&gt;&amp;1 &amp;# 清除环境变量unset JASYPT_ENCRYPTOR_PASSWORD","link":"/zh-CN/carry_coin_jasypt/"},{"title":"Carry-Coin 一个自动化搬砖套利平台","text":"Carry-Coin 是一个套利程序，程序从23年初开始开发至今，目前已经基本稳定，现在将程序的设计整理出来；套利思路很简单：程序监控Cex和Dex平台，针对同一币种发现差价后自动化搬运； carry-config-generator(python) 框架:web3,pandas ; 工程主要负责根据dex,cex，第三方：1inch,odos,dexscreener 数据，进行数据分析最终生成套利配置； carry-core (Java) 一个基于Java的套利核心程序，dex&lt;-&gt;cex套利逻辑的顶层抽象,SwapEngine，SwapStategy, ArbitrageProcessor,CenterExchange,DecenterExchanage,SwapProtocol 等; carry-worker (Java) 框架:Springboot3.2.5,Xchange,Web3j,RxJava3,Guava等；工程基于core实现的不同dex,cex的监控、告警、通知、搬运、买卖逻辑； carry-protocol-adapter(Nodejs) 基于Uniswap-sdk ,jupiter-swap-api(solana)开发的套利协议适配器，适配v2/v3询价； carry-web-front (Nodejs) Vue3.0+TypeScript+Vite5+Ant-Design-Vue等，工程主要管理平台的前端页面，包括套利开关、线上配置、交易数据监控，链上数据监控报表等； carry-web-server (Java) 框架: Spring Cloud Alibaba, Mysql, 管理平台的后端服务； 部署架构 程序截图 技术栈语言 Java 11 Python Nodejs Bash Shell 框架Java Spring Boot JPA Xchange RxJava Guava transmittable-thread-local fastjson web3j lombok assertj jasypt Hutool Slf4j、Logback Python Flask pickledb web3 pandas Nodejs pm2 uniswap-core,V2/v3-sdk solana/web3、spl-token nestjs ethers.js 平台 jeecg-boot","link":"/zh-CN/carry_coin_architecture_1/"},{"title":"ComfyUI 服务系统说明文档","text":"系统概述Comfy 服务系统是一个分布式图像生成服务，由三个主要组件组成： Comfy Service：核心服务节点，负责实际的图像生成任务 Comfy Balancer：负载均衡器，负责任务分发和节点管理 ComfyUI: 负责最终图片渲染生成动作 项目地址 : https://github.com/konbluesky/ComfyUI-Learning 环境依赖 MacOS M1 32G Python3.11 Redis Logdy 轻量级日志查看平台 安装运行说明 服务安装说明 1docker-compose up Logdy 日志平台 : http://localhost:8080 Balancer 后台 : http://localhost:7999 输入用户名：comfy 密码:comfy119.. 后进入swagger页面调试接口 Service 1 : http://localhost:8101 输入用户名：comfy 密码:comfy119.. 后进入swagger页面调试接口 Service 2 : http://localhost:8102 ComfyUI 安装参考 客户端 : Win &amp; MacOS 官网下载 源码安装: https://github.com/comfyanonymous/ComfyUI 安装完成后可直接打开app，也可以用浏览器访问http://localhost:8000 (二者等效) 开发调试 1docker-compose down &amp;&amp; docker-compose up --build 服务配置说明，主要是docker-compose.yml 文件中配置的参数,大部分参数已暴露出来,这里仅列出组件相关参数，忽略logdy和redis的 12345678910111213141516171819202122232425262728293031323334353637383940414243comfy_balancer: build: context: ./comfy-balancer dockerfile: Dockerfile ports: - 7999:7999 depends_on: - redis environment: API_USERNAME: &quot;comfy&quot; API_PASSWORD: &quot;comfy119..&quot; SERVICE_HOST: &quot;comfy_balancer&quot; SERVICE_PORT: 7999 REDIS_HOST: &quot;redis&quot; REDIS_PORT: &quot;6379&quot; REDIS_PASSWORD: &quot;PAssWord123&quot; REDIS_DB: &quot;0&quot; networks: - comfy_netcomfy_service_1: build: context: ./comfy-service dockerfile: Dockerfile ports: - 8101:8101 env_file: - ./comfy-service/.env environment: SERVICE_HOST: &quot;comfy_service_1&quot; SERVICE_PORT: 8101 REDIS_HOST: &quot;redis&quot; REDIS_PORT: &quot;6379&quot; REDIS_PASSWORD: &quot;PAssWord123&quot; REDIS_DB: &quot;0&quot; API_USERNAME: &quot;comfy&quot; API_PASSWORD: &quot;comfy119..&quot; depends_on: - redis - logdy networks: - comfy_net 组件说明Comfy Balancer文件说明1234567comfy-balancer├── config.py├── Dockerfile├── logger.py├── main.py├── requirements.txt└── web.py Comfy Service文件说明1234567891011121314comfy-service├── comfy_api.py├── config.py├── Dockerfile├── health_check.py├── logger.py ├── main.py├── models.py├── paths.py├── requirements.txt├── web.py└── workflows ├── first-workflow-api.json └── first-workflow.json workflows： 配置文件说明，一套流程的api描述文件和模板文件前缀命名需要一致， api文件由ui界面导出 ，操作路径工作流-&gt;导出（API） 模板文件从ComfyUI安装时设置的工作目录获取，路径{WORK_HOME}/user/default/workflows 其他文件12345test├── CompyUI.http # ComfyUI 接口测试的http请求文件├── app-prompt.json # api数据├── logdy_test.http # logdy平台测试的http请求文件└── prompt.json # 模板数据 部署图 效果 ComfyUI workflow设计,对照ComfyUI_StoryDiffusion中Example 渲染结果 Logdy Balancer 仅包含图片生成，任务查询主要接口 Service 包含围绕图片生成，comfyUI节点信息绝大部分接口 待完善 &amp; 思考 基于先实现主要流程和功能的原则,ComfyUI并为使用源码安装,需编写配套安装的shell脚本 告警信息推送功能 comfy_api.py 中workflow.json 每次request都要从文件加载，浪费IO，可改成一次load 扔到redis中； 优化日志记录功能, 目前只有应用日志输出到logdy中，应将comfyUI中执行日志收集过来 思路1: 读comfyUI文件输出到logdy中,但是观察了/Users/xxx/Library/Logs/ComfyUI中的日志，也并不是那完善和详细 没有task具体执行过程中的日志，可能是日志级别问题，后续研究下 思路2: 所有comfyUI web请求逻辑都集中在server.py 中，可在这里二次开发参考service中logger.py的套路，把关键日志通过tcp方式扔到logdy中 comfyUI 通过UI导出api.json 比较麻烦。comfy-cli 好像有这块能力 理想状态： ui中编辑workflow，自动发布到service平台完成并装载，当然取决于workflow的成熟度是否高频，毕竟生成图片全依赖这个，发布后会有版本控制一系列问题 两个服务web启动都用了uvicorn,目前还是main中run单进程work工作，上生产前启动要换成cli调用，这样可以开多work，提高并发能力 balancer 现在还是一个单实例的微网关，这么设计取决于要基于节点资源cpu、gpu处理能力来请求分发,或者基于其他某种业务上的策略分发请求和任务调度，这种重要角色还是应该用撸棒一些的方案 更稳妥方案 ：使用成熟网关OpenResty，集成了Lua脚本、第三方模块和工具链方便定制各种业务规则和场景，二次开发利器。高并发（10万+ QPS）轻松应对。 参考资料 https://github.com/smthemex/ComfyUI_StoryDiffusion https://github.com/comfyanonymous/ComfyUI https://docs.comfy.org/get_started/introduction https://github.com/zjf2671/hh-mcp-comfyui https://logdy.dev/docs/reference/code https://hub.docker.com/r/rickraven/logdy","link":"/zh-CN/comfy_learn/"},{"title":"Miniconda Config","text":"Install12curl -o Miniconda3-latest-MacOSX-x86_64.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.shbash Miniconda3-latest-MacOSX-x86_64.sh Command123456conda init # 初始化conda config --show # 打印配置conda config --set auto_activate_base false # 打开terminal时自动初始化开关eval &quot;$(/Users/xxxx/miniconda3/bin/conda shell.YOUR_SHELL_NAME hook)&quot;# YOUR_SHELL_NAME 替换成你使用的 shell，例如 bash 或 zshconda init --reverse $SHELL bash_profile 123456789101112131415# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=&quot;$('/Users/xxxx/miniconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)&quot;if [ $? -eq 0 ]; then eval &quot;$__conda_setup&quot;else if [ -f &quot;/Users/xxxx/miniconda3/etc/profile.d/conda.sh&quot; ]; then . &quot;/Users/xxxx/miniconda3/etc/profile.d/conda.sh&quot; else export PATH=&quot;/Users/xxxx/miniconda3/bin:$PATH&quot; fifiunset __conda_setup# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;","link":"/zh-CN/conda_mark/"},{"title":"撸毛 Bera 圣诞节","text":"熊链圣诞活动 Box 脚本，Dolomite 存一次Bera奖励2个 Box,集齐 NFT 圣诞开奖。 合约自动发送脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103from web3 import Web3, HTTPProviderfrom itertools import cycleimport timefrom web3.middleware import geth_poa_middlewareimport argparseimport csvfrom proxy import get_proxy_config# 节点列表node_url = [ &quot;https://bera-testnet.nodeinfra.com&quot;, &quot;https://bartio.drpc.org&quot;, &quot;https://bartio.rpc.b-harvest.io&quot;, &quot;https://bartio.rpc.berachain.com&quot;, &quot;https://berat2.lava.build&quot;]# 创建 Web3 对象w3 = Web3()w3.middleware_onion.inject(geth_poa_middleware, layer=0)# 定义一个迭代器，用于循环遍历节点列表node_cycle = cycle(node_urls)def get_next_node(): # 从节点列表中获取下一个节点 return next(node_cycle)def convert_to_checksum_address(address): checksum_address = w3.to_checksum_address(address) return checksum_addressdef send_transaction(sender_address,private_key,token,result_file): nonce = 0 try: # 获取当前节点 current_node = get_next_node() print(&quot;use node : &quot;, current_node) # 设置 Web3 对象的提供程序为当前节点 w3.provider = HTTPProvider(current_node,request_kwargs={&quot;proxies&quot;: get_proxy_config()}) # if (nonce &lt; w3.eth.get_transaction_count(sender_address)): # nonce = w3.eth.get_transaction_count(sender_address) print(&quot;count:&quot;, w3.eth.get_transaction_count(convert_to_checksum_address('0x36864db0396b1ac36c5d6609ded5cc7f8073d08c'))) # 检查是否成功连接到节点 if w3.is_connected(): print(&quot;Connected to Ethereum node&quot;) # 创建交易 transaction = { 'to':convert_to_checksum_address('0x36864db0396b1ac36c5d6609ded5cc7f8073d08c'), 'value': w3.to_wei(0.00001, 'ether'), # 'gas': 22024, # 'maxFeePerGas': w3.to_wei('900', 'gwei'), # 'maxPriorityFeePerGas': w3.to_wei('120', 'gwei'), # 'gasPrice': w3.to_wei('135', 'gwei'), # 设置 gas price 'gas': 500000, 'gasPrice': w3.to_wei('13', 'gwei'), # 设置 gas price 'nonce': w3.eth.get_transaction_count(sender_address), 'chainId': 80084, 'data': '0x33282ded', # 你的数据，以十六进制表示 } # 签名交易 signed_transaction = w3.eth.account.sign_transaction(transaction, private_key) # 发送交易 transaction_hash = w3.eth.send_raw_transaction(signed_transaction.rawTransaction) print(f&quot;Transaction sent. Transaction Hash: {transaction_hash.hex()}&quot;) # 将交易哈希保存到CSV文件 with open(result_file, mode='a', newline='') as file: writer = csv.writer(file) writer.writerow([sender_address,transaction_hash.hex(),token]) time.sleep(2) else: print(&quot;Connection failed&quot;) except Exception as e: # 如果发生异常（例如节点不可用），记录错误并尝试下一个节点 print(f&quot;Error using node {current_node}: {e}&quot;) # if 'already' in e.args['message']: # nonce += 1 # if 'already known' in e.args[0][&quot;message&quot;]: # nonce += 1 # if 'nonce too low: ' in e.args[0][&quot;message&quot;]: # nonce = w3.eth.get_transaction_count(sender_address) # time.sleep(2) # 可以根据需要调整重试间隔import pandas as pdif __name__ == &quot;__main__&quot;: df = pd.read_csv(&quot;0_accounts.csv&quot;) # 将数据转换为元组列表 address_private_key_tuple = list(zip(df['address'], df['private_key'], df['token'])) # 获取选择的发送者信息 while True: for item in address_private_key_tuple: print(&quot;use the sender : &quot;, item[0]) send_transaction(item[0],item[1],item[2],'1_transaction_hashes.csv') # send_transaction() # print(convert_to_checksum_address(sender_address)) TxHash 提交脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116import requestsimport csvimport timeimport base64import osfrom Crypto.Cipher import AESfrom Crypto.Util.Padding import padfrom proxy import get_proxy_configdef encrypt_with_aes256_cbc(plaintext): # 固定的密钥字符串 s = &quot;yQmRxqD#c^DefKhxeuK,2V-M?}3om~eu&quot; # 将字符串转换为字节 key = s.encode(&quot;utf-8&quot;) # print(&quot;key:&quot;, key.hex()) # 生成随机的 16 字节 IV iv = os.urandom(16) # iv = bytes.fromhex(&quot;bcb5d322febaa005286401694c0e0dea&quot;) # print(&quot;iv:&quot;, iv.hex()) # 创建 AES 加密器 cipher = AES.new(key, AES.MODE_CBC, iv) # 使用 PKCS7 填充，并加密数据 plaintext_bytes = plaintext.encode(&quot;utf-8&quot;) encrypted_bytes = cipher.encrypt(pad(plaintext_bytes, AES.block_size)) # 将 IV 和加密数据编码为 Base64 后拼接 iv_base64 = base64.b64encode(iv).decode(&quot;utf-8&quot;) encrypted_base64 = base64.b64encode(encrypted_bytes).decode(&quot;utf-8&quot;) return iv_base64 + encrypted_base64def send_request(account,txHash, token,max_retries=3, retry_delay=3): headers = { 'accept': '*/*', 'accept-language': 'zh,zh-CN;q=0.9,en;q=0.8,und;q=0.7', 'authorization': f'Bearer {token}', 'content-type': 'application/json', 'origin': 'https://beratown.dapdap.net', 'priority': 'u=1, i', 'referer': 'https://beratown.dapdap.net/', 'sec-ch-ua': '&quot;Google Chrome&quot;;v=&quot;131&quot;, &quot;Chromium&quot;;v=&quot;131&quot;, &quot;Not_A Brand&quot;;v=&quot;24&quot;', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': '&quot;macOS&quot;', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'cross-site', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36', } for attempt in range(max_retries): try: json_data = { 'action_type': 'Lending', 'account_id': account, 'template': 'Dolomite', 'sub_type': 'Supply', 'action_switch': 0, 'action_status': 'Success', 'tx_id': txHash, 'action_network_id': 'Berachain bArtio', 'chain_id': 80084, 'action_title': 'Deposit 0.000 BERA on Dolomite', 'action_tokens': '[&quot;BERA&quot;]', 'action_amount': '0.0001', 'ss': '', 'source': 'lending', 'wallet': 'OKX Wallet', } t = f&quot;template=Dolomite&amp;action_type=Lending&amp;tx_hash={txHash}&amp;chain_id=80084&amp;time={int(time.time())}&quot; print(&quot;hashTx:&quot; + txHash) # print(&quot;raw:&quot; + t) encrypted_data = encrypt_with_aes256_cbc(t) json_data['ss'] = encrypted_data # print(&quot;encrypted:&quot; + encrypted_data) response = requests.post('https://testnet-api.beratown.app/api/action/add', headers=headers, json=json_data, proxies=get_proxy_config()) print(f&quot;Response for address:{account} txHash {txHash}: {response.status_code}&quot;) print(response.json()) if response.status_code == 200: return response.status_code, response.json() else: print(f&quot;Request failed with status code {response.status_code}. {response.text} Retrying...&quot;) except Exception as e: print(f&quot;An error occurred: {e}. Retrying...&quot;) time.sleep(retry_delay) print(f&quot;Failed to send request after {max_retries} attempts.&quot;) return None, Noneif __name__ == &quot;__main__&quot;: csv_file_path = '1_transaction_hashes.csv' # CSV文件路径 output_csv_file_path = '2_successful_hashes.csv' # 输出CSV文件路径 with open(csv_file_path, mode='r') as infile, open(output_csv_file_path, mode='a', newline='') as outfile: reader = csv.reader(infile) writer = csv.writer(outfile) for row in reader: if row: # 确保行不为空 address = row[0].strip() txHash = row[1].strip() token = row[2].strip() status_code, response = send_request(address, txHash,token) writer.writerow([address,txHash, token,status_code, response]) 自动开箱 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import requestsimport csvimport logging# 配置日志记录logging.basicConfig( handlers=[ logging.FileHandler('claim.log'), # 将日志写入文件 logging.StreamHandler() # 同时输出到终端 ], level=logging.INFO, # 日志级别 format='%(asctime)s - %(levelname)s - %(message)s', # 日志格式 datefmt='%Y-%m-%d %H:%M:%S' # 日期格式)headers = { 'accept': '*/*', 'accept-language': 'zh,zh-CN;q=0.9,en;q=0.8,und;q=0.7', 'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjozMTcwNTc1LCJleHAiOjE3MzczOTA0NjUsInN1YiI6ImFjY2VzcyJ9.pLUIJ0ClYe8vycR_uJm_OJ8AivvdJ-f-6S4b6VET9so', 'content-type': 'application/json', 'origin': 'https://beratown.dapdap.net', 'priority': 'u=1, i', 'referer': 'https://beratown.dapdap.net/', 'sec-ch-ua': '&quot;Google Chrome&quot;;v=&quot;131&quot;, &quot;Chromium&quot;;v=&quot;131&quot;, &quot;Not_A Brand&quot;;v=&quot;24&quot;', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': '&quot;macOS&quot;', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'cross-site', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',}def send_get_request(account): json_data = { 'all': False, } response1 = requests.post('https://testnet-api.beratown.app/api/mas/reward/draw', headers=headers, json=json_data) url = f'https://testnet-api.beratown.app/api/mas/user/{account}' logging.info(f'Sending GET request to {url}') response2 = requests.get(url, headers=headers) logging.info(f'Received response with status code {response1.status_code} {response2.status_code}') return response1.status_code,response1.text,response2.status_code, response2.textif __name__ == &quot;__main__&quot;: input_csv_file_path = '2_successful_hashes_1.csv' # 输入CSV文件路径 output_csv_file_path = '3_claim_results.csv' # 输出CSV文件路径 logging.info(f'Reading successful hashes from {input_csv_file_path}') logging.info(f'Writing results to {output_csv_file_path}') with open(input_csv_file_path, mode='r') as infile, open(output_csv_file_path, mode='w', newline='') as outfile: reader = csv.reader(infile) writer = csv.writer(outfile) # 写入表头 writer.writerow( ['txHash', 'request_number', 'draw_status_code', 'draw_response', 'claim_status_code', 'claim_response']) for row in reader: if row: # 确保行不为空 address = row[0].strip() txHash = row[1].strip() logging.info(f'Processing txHash: {txHash}') for i in range(2): # 执行两次GET请求 status_code1, response1, status_code2, response2 = send_get_request(address) writer.writerow([txHash, i + 1, status_code1, response1, status_code2, response2]) logging.info( f'Request {i + 1} for {address} txHash {txHash} completed with status code {status_code1} {status_code2}')","link":"/zh-CN/freebie_hunting_bera_chain/"},{"title":"Google 2FA 脚本","text":"批量显示Google 2FA 工具，5秒刷新一次 secrets.csv 123456789101112131415username,secretiAvloyola,ENOG7VLRJJ7GDNZJLilBlue561,IWPTHMCHSR74EOSHKwaciWorsnop,TUXN5TNLTKOPTJEYvikeshchotai,L333DPD5JHXF3O2Kperaltasocimo,UH4EDK7425BFCXSHmakzuzu,OUIG375O7OARDXLJJsaFikitha,AIWBIBQGXZK3ZDE3limliangtung,HHD2VM5LHCV6TDOVsinhde18,L6LYS4ECQL5KKPFFActionDT,O64IEGT5NPCOHCQtimansur,3ASN5ZIGJH4ICYUXDarmyrez,BTKNH5OMOMPZ7CFYaninditamario,G2VHH4IHFE367PNWizzanfurkan,EYP7VV6AK6EIDIJB 批量显示验证码脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import csvimport datetimeimport pyotpimport timeimport osimport base64# 定义读取CSV文件的函数def read_secrets_from_csv(csv_file_path): secrets = [] with open(csv_file_path, mode='r') as file: reader = csv.DictReader(file) for row in reader: secrets.append(row) return secrets# 定义验证Base32密钥的函数def is_valid_base32(secret): try: # 尝试解码，如果失败则说明不是有效的Base32 base64.b32decode(secret, casefold=True) return True except (base64.binascii.Error, ValueError): return False# 定义生成2FA验证码的函数def generate_2fa_codes(secrets): codes = [] for secret in secrets: if is_valid_base32(secret['secret']): totp = pyotp.TOTP(secret['secret']) code = totp.now() codes.append({'username': secret['username'], 'code': code}) else: codes.append({'username': secret['username'], 'code': '无效的Base32密钥'}) return codes# 主函数def main(): csv_file_path = '2fa/secrets.csv' # 请根据实际情况修改CSV文件路径 secrets = read_secrets_from_csv(csv_file_path) while True: os.system('cls' if os.name == 'nt' else 'clear') # 清屏 codes = generate_2fa_codes(secrets) print(f&quot;时间:{datetime.datetime.now()}&quot;) for entry in codes: print(f&quot;用户 {entry['username']} 的当前2FA验证码是: {entry['code']}&quot;) time.sleep(5) # 每30秒刷新一次if __name__ == &quot;__main__&quot;: main()","link":"/zh-CN/google-2fa/"},{"title":"修复Python进程PID不一致问题","text":"背景在使用Bash脚本启动Python进程时，遇到了一个常见的问题：记录的进程ID（PID）与实际运行的PID不一致。这种情况可能导致进程管理的混乱，尤其是在需要停止或重启进程时。本文将分析导致这一问题的原因，并提供解决方案。 问题描述在我们的start.sh脚本中，使用了以下代码来启动Python进程：","link":"/zh-CN/fix_python_process_pid_issue/"},{"title":"Hexo 站点的SEO配置","text":"Hexo 站点的SEO配置Hexo Blog 配置SEO主要用到两个插件hexo-generator-sitemap，hexo-submit-urls-to-search-engine 重要步骤 Google账号的话激活Google Cloud 根据文档步骤完成服务账号创建和密钥创建 密钥创建成功后下载密钥的json文件到hexo根目录下，并在_config.yml中配置 https://www.google.com/webmasters/verification/home 会自动跳到新后台,使用『网址前缀』方式验证所有权，会生成googleaXXXXXX.html 文件 download 下载到hexo 的source目录下 完成站点验证 登录https://search.google.com/search-console 在『设置』-&gt; 『用户和权限』 -&gt;『添加用户』 将密钥json文件中的client_email中邮箱（就是第一步在Google中创建的服务账号对应的邮箱）添加 指定权限为所拥有者 代码123npm install hexo-submit-urls-to-search-engine --savenpm install hexo-generator-sitemap --save Config 配置123456789101112131415161718hexo_submit_urls_to_search_engine: submit_condition: count #链接被提交的条件，可选值：count | period 现仅支持count count: 10 # 提交最新的10个链接 period: 900 # 提交修改时间在 900 秒内的链接 google: 1 # 是否向Google提交，可选值：1 | 0（0：否；1：是） bing: 0 # 是否向bing提交，可选值：1 | 0（0：否；1：是） baidu: 0 # 是否向baidu提交，可选值：1 | 0（0：否；1：是） txt_path: submit_urls.txt # 文本文档名， 需要推送的链接会保存在此文本文档里 baidu_host: https://konbluesky.github.io # 在百度站长平台中注册的域名 baidu_token: #请按照文档说明获取 # 请注意这是您的秘钥， 所以请不要把它直接发布在公众仓库里! bing_host: https://konbluesky.github.io # 在bing站长平台中注册的域名 bing_enable_indexnow: false # 是否用 indexNow 提交链接给必应: true (Yes) | false (No). 只有 2.1.1 及之后的版本才可以开启这个功能。 bing_token: #请按照文档说明获取 # 请注意这是您的秘钥， 所以请不要把它直接发布在公众仓库里! google_host: https://konbluesky.github.io # 在google站长平台中注册的域名 google_key_file: key.json #存放google key的json文件，放于网站根目录（与hexo _config.yml文件位置相同），请不要把json文件内容直接发布在公众仓库里! google_proxy: 0 replace: 0 # 是否替换链接中的部分字符串，可选值：1 | 0（0：否；1：是） find_what: http://konbluesky.github.io 推送成功12345678Google response: { urlNotificationMetadata: { url: 'https://konbluesky.github.io/2024/11/27/hummingbot_gateway/' }}Google response: { urlNotificationMetadata: { url: 'https://konbluesky.github.io/2025/01/14/python_py_spy/' }} 问题处理1234567Google response: { error: { code: 403, message: 'Permission denied. Failed to verify the URL ownership.', status: 'PERMISSION_DENIED' }} https://github.com/cjh0613/hexo-submit-urls-to-search-engine/issues/18 参见重要步骤中的3 参考文档 https://github.com/cjh0613/hexo-submit-urls-to-search-engine 插件github地址 https://cjh0613.com/20200603HexoSubmitUrlsToSearchEngine hexo-submit-urls-to-search-engine 插件使用说明!! Indexing API 允许网站所有者在发布招聘信息或直播时直接通知 Google 添加或删除视频页面。这允许 Google 安排页面进行新的抓取， 可以带来更高质量的用户流量。Indexing API 只能用于抓取具有以下特征的页面： JobPosting 或 嵌入在 VideoObject 中的 BroadcastEvent 。对于包含许多短期页面（例如招聘信息或直播视频）的网站，Indexing API 允许单独推送更新，从而使搜索结果中的内容保持最新。 https://github.com/hexojs/hexo-generator-sitemap 用来生成sitemap.xml 文件 https://developers.google.cn/search/apis/indexing-api/v3/prereqs https://zhuanlan.zhihu.com/p/651590960","link":"/zh-CN/hexo_add_seo_push_feature/"},{"title":"Hummingbot Create First Strategy Bot","text":"使用simple_amm策略创建第一个机器人 使用命令: 123start --script [SCRIPT NAME]create --script-config [SCRIPT_FILE]start --script [SCRIPT_FILE] --conf [SCRIPT_CONFIG_FILE] 初始的文件目录 12345678910111213141516(hummingbot) root@vmi2090919:~/hummingbot/conf# tree.├── __init__.py├── conf_client.yml├── conf_fee_overrides.yml├── connectors│ ├── __init__.py│ ├── mexc.yml│ └── okx.yml├── controllers│ └── __init__.py├── hummingbot_logs.yml├── scripts│ └── __init__.py└── strategies └── __init__.py hummingbot cli中 通过下列指令创建基本策略 123456789101112131415161718&gt;&gt;&gt; create --script-config simple_pmm For more information, please visit https://pyperclip.readthedocs.io/en/latest/introduction.html#not-implemented-erro r (See log file for stack trace dump)Exchange where the bot will trade &gt;&gt;&gt; mexcTrading pair in which the bot will place orders &gt;&gt;&gt; MX-USDTOrder amount (denominated in base asset) &gt;&gt;&gt; 0.01Bid order spread (in percent) &gt;&gt;&gt; 0.001Ask order spread (in percent) &gt;&gt;&gt; 0.001Order refresh time (in seconds) &gt;&gt;&gt; 15Price type to use (mid or last) &gt;&gt;&gt; midEnter a new file name for your configuration &gt;&gt;&gt; conf_simple_pmm_1.ymlA new config file has been created: conf_simple_pmm_1.yml ps: 配置过程中要终止配置的话，使用快捷键ctrl+x 查看文件目录，新配置已生成 1234567891011121314151617(hummingbot) root@vmi2090919:~/hummingbot/conf# tree.├── __init__.py├── conf_client.yml├── conf_fee_overrides.yml├── connectors│ ├── __init__.py│ ├── mexc.yml│ └── okx.yml├── controllers│ └── __init__.py├── hummingbot_logs.yml├── scripts│ ├── __init__.py│ └── conf_simple_pmm_1.yml└── strategies └── __init__.py conf_simple_pmm_1.yml 内容 12345678script_file_name: simple_pmm.pyexchange: mexctrading_pair: MX-USDTorder_amount: 0.01bid_spread: 0.001ask_spread: 0.001order_refresh_time: 15price_type: mid 使用start --script simple_pmm --conf conf_simple_pmm_1.yml 启动bot 错误123456789102024-11-15 13:10:31,262 - 2684330 - hummingbot.connector.exchange.mexc.mexc_exchange.MexcExchange - INFO - Network status has changed to NetworkStatus.CONNECTED. Starting networking...2024-11-15 13:10:31,715 - 2684330 - hummingbot.connector.exchange.mexc.mexc_api_order_book_data_source.MexcAPIOrderBookDataSource - ERROR - Unexpected error occurred subscribing to order book trading and delta streams...Traceback (most recent call last): File &quot;/root/hummingbot/hummingbot/connector/exchange/mexc/mexc_api_order_book_data_source.py&quot;, line 76, in _subscribe_channels symbol = await self._connector.exchange_symbol_associated_to_pair(trading_pair=trading_pair) File &quot;hummingbot/connector/exchange_base.pyx&quot;, line 97, in exchange_symbol_associated_to_pair return symbol_map.inverse[trading_pair] File &quot;/root/miniconda3/envs/hummingbot/lib/python3.10/site-packages/bidict/_base.py&quot;, line 524, in __getitem__ return self._fwdm[key]KeyError: 'MX-USDT' Mexc 中并不是所有交易对都支持api交易的，交易对要到https://api.mexc.com/api/v3/defaultSymbols接口中检查下换了个PNUT-USDT交易对,正常交易了。 关于 PMM with Price Shift and Dynamic Spreads simple_amm.py 使用的策略 参考资料关于 PMM with Price Shift and Dynamic Spreads","link":"/zh-CN/hummingbot_create_simple_pmm_bot/"},{"title":"Hummingbot Dashboard","text":"Hummingbot Dashboard Hummingbot Dashboard 是一款开源应用，旨在帮助用户创建、回测和优化各种算法交易策略。一旦策略得到完善，它们可以作为 Hummingbot 实例部署到实盘交易模式中，从策略制定到实际交易执行实现无缝衔接。 功能 机器人编排：部署和管理多个 Hummingbot 实例 策略回测与优化：通过历史数据评估策略表现，并使用 Optuna 进行优化 一键部署：轻松将策略部署为 Hummingbot 实例，支持模拟或实盘交易 性能分析监控：监控并分析已部署策略的表现 凭证管理：创建和管理 API 密钥的独立账户 文档：https://hummingbot.org/dashboard/ 安装Dashboard 两种方式build from sourcehttps://github.com/hummingbot/dashboard#installation docker先装docker compose 12345678sudo curl -L &quot;https://github.com/docker/compose/releases/download/v2.28.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --versiongit clone https://github.com/hummingbot/deploycd deploybash setup.sh 参考资料 Hummingbot stategies_v1","link":"/zh-CN/hummingbot_dashboard/"},{"title":"Hummingbot：开源的加密货币高频交易机器人","text":"Hummingbot 是一个开源的高频交易机器人框架，旨在为加密货币市场提供自动化交易工具。无论是市场做市（market making）、套利（arbitrage），还是跨交易所市场做市（cross-exchange market making），Hummingbot 都为用户提供了多种实用的策略模板，帮助用户轻松上手高频交易，参与到加密货币交易市场中。 Hummingbot 的主要特点1. 开源与社区驱动Hummingbot 是一个开源项目，其代码公开透明，用户可以根据自身需求对代码进行修改，也可以为社区贡献代码。社区驱动的开发模式使得 Hummingbot 不断进步，拥有活跃的支持和开发者社群，并定期发布更新和新功能。 2. 支持多种交易所Hummingbot 支持多个主流的中心化交易所（CEX）和去中心化交易所（DEX），如 Binance、Coinbase Pro、FTX、Uniswap、Balancer 等。它具有一个插件系统，使得开发者可以为还不支持的交易所编写接口，以满足更多的市场需求。 3. 灵活的策略配置Hummingbot 提供多种内置交易策略模板，涵盖了： 简单市场做市（Market Making）： 通过挂买卖单，赚取价差。 套利（Arbitrage）： 利用不同交易所之间的价格差获利。 跨交易所做市（Cross-Exchange Market Making）： 在多个交易所间挂单捕捉价差。 用户可以通过配置文件轻松调整策略参数，例如控制交易频率、订单大小、价差范围等，使得策略更加灵活、适应不同市场情况。 4. 用户友好的 CLI 界面Hummingbot 提供了简洁的命令行界面（CLI），用户可以快速配置和监控机器人的运行状态，并且支持实时监控和日志记录。对于希望快速上手交易的用户来说，这个界面非常友好。 5. 强大的策略开发支持对于有编程基础的用户，Hummingbot 支持 Python 自定义交易策略。用户可以根据市场需求和个人交易风格调整策略，例如自定义套利触发条件、调整加仓和减仓逻辑等。这一特性让 Hummingbot 成为一个灵活的量化交易框架。 6. 灵活的部署方式Hummingbot 支持本地部署，也可以部署在云服务器上，适应不同用户的需求。它能够与各类外部数据源、交易所的 API 无缝集成，适合于大规模实时交易需求。 Hummingbot 的应用场景Hummingbot 支持的策略广泛适用于以下场景： 市场做市（Market Making）： 提供流动性，通过在买卖之间的价差获利。 套利交易（Arbitrage）： 抓住不同交易所之间的价差机会获利。 跨交易所做市（Cross-Exchange Market Making）： 同时在两个或多个交易所挂买卖单，以捕捉价差。 总结Hummingbot 是一个高度灵活且功能强大的开源交易机器人，对希望参与加密货币高频交易的开发者和量化交易者来说，是一个值得尝试的选择。无论你是交易新手，还是经验丰富的量化交易员，Hummingbot 都提供了丰富的功能和高效的工具，助你在加密货币市场中捕捉更多机会。","link":"/zh-CN/hummingbot_info/"},{"title":"Hummingbot Gateway AMM Middleware","text":"Hummingbot Gateway 是一个 REST API，它公开与各种区块链（钱包、节点和链交互）和去中心化交易所（定价、交易和流动性提供）的连接。它用 Typescript 编写，并利用现有的区块链和 DEX SDK。使用网关的优势在于它提供了一种与编程语言无关的方法来与区块链和 DEX 进行交互。 官方文档 Install Gateway Github 步骤123456789101112# Install dependenciesyarn# Complile Typescript into JS$ yarn build# Run Gateway setup script, which helps you set configs and CERTS_PATH$ chmod a+x gateway-setup.sh$ ./gateway-setup.sh# Start the Gateway server using PASSPHRASE$ yarn start --passphrase=&lt;PASSPHRASE&gt; ./gateway-setup.sh 之前需要到hummingBot中执行gateway generate-certs 生成certs文件,复制路径 1234567891011121314151617181920212223242526272829303132333435 base  14:35:00  ...work/digital-trade/gateway  $ ./gateway-setup.sh=============== SETUP GATEWAY ===============Do you want to copy over client certificates (Y/N) &gt;&gt;&gt; yEnter path to the Hummingbot certs folder &gt;&gt;&gt; /Users/xxxx/work/digital-trade/hummingbot/certsFiles successfully copied from /Users/xxxx/work/digital-trade/hummingbot/certs to /Users/xxxx/work/digital-trade/gateway/certsℹ️ Confirm if this is correct: Copy configs FROM: /Users/xxxx/work/digital-trade/gateway/src/templates Copy configs TO: /Users/xxxx/work/digital-trade/gateway/conf Copy certs FROM: /Users/xxxx/work/digital-trade/hummingbot/certs Copy certs TO: /Users/xxxx/work/digital-trade/gateway/certsDo you want to proceed? [Y/N] &gt;&gt;&gt; ymkdir: /Users/xxxx/work/digital-trade/gateway/conf: File existsFiles successfully copied from /Users/xxxx/work/digital-trade/gateway/src/templates to /Users/xxxx/work/digital-trade/gateway/confmkdir: /Users/xxxx/work/digital-trade/gateway/conf/lists: File existsFiles successfully copied from /Users/xxxx/work/digital-trade/gateway/src/templates/lists to /Users/xxxx/work/digital-trade/gateway/confReplaced list locations in: conf/celo.ymlReplaced list locations in: conf/osmosis.ymlReplaced list locations in: conf/cronos.ymlReplaced list locations in: conf/binance-smart-chain.ymlReplaced list locations in: conf/ethereum.ymlReplaced list locations in: conf/polygon.ymlReplaced list locations in: conf/avalanche.ymlReplaced list locations in: conf/harmony.ymlReplaced list locations in: conf/xdc.yml 启动后 1234567891011$ yarn start --passphrase=123456yarn run v1.22.4$ /bin/bash ./startup.sh --passphrase=abcde2024-11-27 08:04:55 | info | Gateway Version: 2.1.02024-11-27 08:04:55 | info | ⚡️ Starting Gateway API on port 15888...(node:48566) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.(Use `node --trace-deprecation ...` to show where the warning was created)2024-11-27 08:04:55 | info | The gateway server is secured behind HTTPS.2024-11-27 08:04:55 | info | ⚡️ Swagger listening on port 8080. Read the Gateway API documentation at 127.0.0.1:8080::ffff:127.0.0.1 - - [27/Nov/2024:06:44:57 +0000] &quot;GET /connectors HTTP/1.1&quot; 200 4181 &quot;-&quot; &quot;Python/3.10 aiohttp/3.11.7&quot;::ffff:127.0.0.1 - - [27/Nov/2024:06:44:57 +0000] &quot;GET /chain/config HTTP/1.1&quot; 200 18304 &quot;-&quot; &quot;Python/3.10 aiohttp/3.11.7&quot;","link":"/zh-CN/hummingbot_gateway/"},{"title":"Hummingbot Macos下搭建开发调试环境","text":"HummingBot中文社区组织交易比赛,时间从11.25-12.2号为期一周,25号折腾了一上午BN子账号API token问题,到底还是被BN的统一账户模式坑了下.(感谢社区Dolm的耐心帮助.) 今天抽空把本地环境部署了下,方便交易策略的开发和调试. 之前在ubuntu的云主机上运行hummingBot过程比较丝滑,倒没碰到什么大问题;本地是Macos环境，乱七八糟的环境太乱了,过然还是碰到了一些问题,记录下. 官方文档Install for macos 编译问题 ios,complex头文件找不到，报error 123456789101112131415161718192021222324252627282930313233343536373839404142434445building 'hummingbot.strategy.pure_market_making.pure_market_making_order_tracker' extensionclang++ -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -Ihummingbot/core/data_type -Ihummingbot/core -I/Users/konbluesky/miniconda3/envs/hummingbot/lib/python3.10/site-packages/numpy/core/include -I/Users/konbluesky/miniconda3/envs/hummingbot/include/python3.10 -c hummingbot/strategy/pure_market_making/pure_market_making_order_tracker.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/pure_market_making/pure_market_making_order_tracker.ohummingbot/strategy/cross_exchange_market_making/order_id_market_pair_tracker.cpp:1254:10: fatal error: 'ios' file not found1254 | #include &quot;ios&quot;| ^~~~~hummingbot/strategy/avellaneda_market_making/avellaneda_market_making.cpp:1257:10: fatal error: 'ios' file not found1257 | #include &quot;ios&quot;| ^~~~~hummingbot/strategy/cross_exchange_mining/cross_exchange_mining.cpp:1258:10: fatal error: 'string' file not found1258 | #include &lt;string&gt;| ^~~~~~~~1 error generated.hummingbot/strategy/cross_exchange_mining/order_id_market_pair_tracker.cpp:1254:10: fatal error: 'ios' file not found1254 | #include &quot;ios&quot;| ^~~~~building 'hummingbot.strategy.strategy_base' extensionclang++ -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -Ihummingbot/core/data_type -Ihummingbot/core -I/Users/konbluesky/miniconda3/envs/hummingbot/lib/python3.10/site-packages/numpy/core/include -I/Users/konbluesky/miniconda3/envs/hummingbot/include/python3.10 -c hummingbot/strategy/strategy_base.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/strategy_base.ohummingbot/strategy/order_book_asset_price_delegate.cpp:1256:10: fatal error: 'ios' file not found1256 | #include &quot;ios&quot;| ^~~~~hummingbot/strategy/order_tracker.cpp:1256:10: fatal error: 'string' file not found1256 | #include &lt;string&gt;| ^~~~~~~~1 error generated.hummingbot/strategy/pure_market_making/pure_market_making.cpp:1257:10: fatal error: 'ios' file not found1257 | #include &quot;ios&quot;| ^~~~~building 'hummingbot.strategy.strategy_py_base' extensionclang++ -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -fPIC -O2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -Ihummingbot/core/data_type -Ihummingbot/core -I/Users/konbluesky/miniconda3/envs/hummingbot/lib/python3.10/site-packages/numpy/core/include -I/Users/konbluesky/miniconda3/envs/hummingbot/include/python3.10 -c hummingbot/strategy/strategy_py_base.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/strategy_py_base.ohummingbot/strategy/pure_market_making/pure_market_making_order_tracker.cpp:1256:10: fatal error: 'string' file not found1256 | #include &lt;string&gt;| ^~~~~~~~1 error generated.1 error generated.1 warning and 1 error generated.1 error generated.1 error generated.hummingbot/strategy/strategy_base.cpp:1256:10: fatal error: 'ios' file not found1256 | #include &quot;ios&quot;| ^~~~~1 error generated.hummingbot/strategy/strategy_py_base.cpp:1256:10: fatal error: 'ios' file not found1256 | #include &quot;ios&quot;| ^~~~~1 error generated. 检查conda环境envs/hummingbot/include中确实没有对应的头文件,怀疑可能是前不久刚升级系统,commandLineTool被更新了,应该导致基础库没了为了省力直接干掉/Library/Developer/CommandLineTools目录,执行sudo xcode-select --install 重新安装. 干掉conda的hummingbot环境,因为之前是用老tool执行的 重新执行./install 和 ./compile,出现新错误 12345gbot/strategy/strategy_py_base.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/strategy_py_base.ocreating build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/twapx86_64-apple-darwin13.4.0-clang++ -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden -fmessage-length=0 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -D_FORTIFY_SOURCE=2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -I/Users/konbluesky/miniconda3/envs/hummingbot/lib/python3.10/site-packages/numpy/core/include -I/Users/konbluesky/miniconda3/envs/hummingbot/include/python3.10 -c hummingbot/strategy/spot_perpetual_arbitrage/dummy.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/spot_perpetual_arbitrage/dummy.ox86_64-apple-darwin13.4.0-clang++ -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden -fmessage-length=0 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -D_FORTIFY_SOURCE=2 -isystem /Users/konbluesky/miniconda3/envs/hummingbot/include -I/Users/konbluesky/miniconda3/envs/hummingbot/lib/python3.10/site-packages/numpy/core/include -I/Users/konbluesky/miniconda3/envs/hummingbot/include/python3.10 -c hummingbot/strategy/twap/dummy.cpp -o build/temp.macosx-10.13-x86_64-cpython-310/hummingbot/strategy/twap/dummy.oerror: command 'x86_64-apple-darwin13.4.0-clang++' failed: No such file or directory 手动export到上下文 1export CXX=clang 执行./start Pycharm 配置 添加conda HummingBot的interpreter ./start.sh文件中是通过hummingbot_quickstart.py 来启动的,有三个参数PASSWORD,FILENAME,CONFIG 这里先暂时用不到.所以Pycharm中直接Run bin/hummingbot_quickstart.py 就可以了; HummingBot 是命令行UI程序,使用的是prompt_toolkit,这个框架在console中输出有特殊要求,所以如果碰到下面错误 不要慌,在Run/Debug Configurations中 勾选下面Emulate terminal in output console配置 再次Run Ok. 开发环境完毕. 收工","link":"/zh-CN/hummingbot_dev_env/"},{"title":"Hummingbot Install(macos)","text":"Hummingbot Macos 安装步骤 安装要求（macos） Component Specification Operating System MacOS 12+ - Intel x86 or Apple Silicon (M1 / M2 / M3) Memory 4 GB RAM per instance Storage 5 GB HDD space per instance CPU At least 1 vCPU per instance / controller 1xcode-select --install 官方建议用conda做环境MacOS with Intel x86: 12curl -o Miniconda3-latest-MacOSX-x86_64.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.shbash Miniconda3-latest-MacOSX-x86_64.sh MacOS with Apple Silicon (M1 / M2 / M3): 12curl -o Miniconda3-latest-MacOSX-x86_64.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.shbash Miniconda3-latest-MacOSX-x86_64.sh 12345git clone https://github.com/hummingbot/hummingbot.gitcd hummingbot./installconda activate hummingbot./compile 如果安装后conda命令无法识别，可以尝试将miniconda3安装目录下的bin目录添加到环境变量中。/root/.bashrc中添加：export PATH=&quot;/Users/your_username/miniconda3/bin:$PATH&quot;然后执行source /root/.bashrc使环境变量生效。 1./start.sh 启动界面 在命令行ui界面，设置密码后进入主界面 参考资料 Hummingbot Install(macos)","link":"/zh-CN/hummingbot_install/"},{"title":"Hummingbot 目录结构","text":"Hummingbot 目录结构 安装后目录123456789hummingbot ┣ conf ┣ connectors ┣ strategies ┣ scripts ┣ logs ┣ data ┣ scripts ┣ hummingbot /conf：配置文件的通用文件夹 /conf/connectors：配置 Exchange API 密钥 /conf/strategies：配置策略文件,在cli-ui中通过create和import命令创建或导入策略 /conf/scripts：编写脚本配置文件,create --script-config /logs：脚本和策略生成的日志文件 /data：用于记录脚本和策略执行的交易的 SQLite 数据库和 CSV 文件 /scripts：此文件夹包含示例脚本，可以在此处添加新脚本，以使其可供start命令使用","link":"/zh-CN/hummingbot_post_install/"},{"title":"Hummingbot Strategies v1","text":"Hummingbot 内置很多策略模板分v1/v2，目前社区表示全力发展v2版的策略，v1虽然官方不维护了，但是不影响我们学习； v1的策略在/hummingbot/strategy目录里 策略 描述 pure_market_making Hummingbot 的原始单对市场做市策略 cross_exchange_market_making 一种通过在另一个交易所对冲来减轻库存风险的做市策略 amm_arb 一种利用 AMM 去中心化交易所与其他交易所之间价格差异的套利策略 avellaneda_market_making 基于经典的 Avellaneda-Stoikov 论文的单对市场做市策略 cross_exchange_mining 社区维护的交叉交易所做市策略的修改版 hedge 使用永续合约对冲现货交易所的库存风险 liquidity_mining 使用单一的基础币或报价币在多个交易对上提供流动性 perpetual_market_making 社区维护的永续市场做市策略 spot_perpetual_arbitrage 利用现货市场与永续合约交易所之间的价格差异进行套利 twap 在一定时间段内批量下限价单 amm-v3-lp 动态维护 AMM 去中心化交易所中的区间流动性头寸 参考资料 Hummingbot stategies_v1","link":"/zh-CN/hummingbot_strategy_v1/"},{"title":"Internet Computer (IC)","text":"ICP 的全称(Internet Computer Protocol) 互联网计算机协议，是DFINITY 基金会（https://dfinity.org） https://internetcomputer.org/docs/current/home https://github.com/dfinity/sdk 支持的语言 Motoko Typescript Rust Solidity 支持的框架 Juno React Testnets","link":"/zh-CN/ic_hello/"},{"title":"NockChain Install(macos)","text":"NockChain 安装步骤 https://www.nockchain.org/ https://www.nockchain.org/faq/ https://github.com/zorp-corp/nockchain 环境（macos） Component Specification Operating System MacOS 12+ - Intel x86 or Apple Silicon (M1 / M2 / M3) Memory 32 GB RAM 安装rust环境1curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh make build-hoon-all123make build-hoon-all 构建日志: build-hoon-all.log make build123make build 构建日志: build.log 1./start.sh Leader启动界面","link":"/zh-CN/nockchain_install/"},{"title":"Hummingbot Strategies v2","text":"组件v2 对比 v1 来说，架构做了调整，多了几个组件更好的工作和解耦 脚本（Script）：所有策略的入口点，这个Python文件负责协调整个策略的执行。它可以是一个包含所有策略逻辑的简单文件，或者是一个加载一个或多个控制器的文件。 市场数据提供器（Market Data Provider）：用于访问交易所的市场数据的单一入口，比如历史OHCLV（开盘价、高点、低点、收盘价、成交量）K线数据、订单簿数据和交易记录。 执行器（Executor）：根据用户预设管理订单和仓位，确保根据策略指令下单、修改或取消订单。 控制器（Controller）：基于策略控制器的基础类（如方向性策略或做市策略）定义一个交易策略。 继承关系 V1 策略 策略基类（StrategyBase）：StrategyBase 是所有策略的 Cython 基类，而 StrategyPyBase 继承自它，并作为所有 Python 基础策略的根类。 V1 脚本（Scripts）：ScriptStrategyBase 是在上述类的基础上构建的，创建简单策略变得更加容易。这个类目前仍然支持，但后面可能会被弃用。所以建议在新脚本实现中使用 StrategyV2Base。 控制器与 V2 脚本 V2 策略基类（StrategyV2Base）：StrategyV2Base 继承自 ScriptStrategyBase，但它使用执行器（Executors）来管理订单，而不再通过 buy() / sell() 方法。控制器（Controllers）在此基础上进一步扩展，作为通过事件队列松散耦合的附加组件。 请务必牢记继承结构，这会大大帮助理解如何编写自己的自定义策略。 参考资料 Hummingbot stategies_v2","link":"/zh-CN/hummingbot_strategy_v2/"},{"title":"BSC节点区块监控脚本","text":"脚本主要监听私有BSC节点区块状态，如发生区块漏块过多，发送告警消息到DD群中，carry-coin调整rpc访问策略； 监控脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123from web3 import Web3import timeimport threadingimport sysimport loggingfrom logging.handlers import TimedRotatingFileHandlerimport osfrom stop_event_trigger import StopEventTrigger# 日志配置log_dir = &quot;logs&quot;if not os.path.exists(log_dir): os.makedirs(log_dir)app_name=&quot;block_monitor-7.143&quot;can_call=Falsestop_event_trigger = StopEventTrigger()log_file = os.path.join(log_dir, &quot;block_monitor.log&quot;)# 创建一个TimedRotatingFileHandler，用于按照日期切割日志文件file_handler = TimedRotatingFileHandler(log_file, when=&quot;midnight&quot;, interval=1, backupCount=7, encoding='utf-8')file_handler.setFormatter(logging.Formatter(app_name+' %(asctime)s - %(levelname)s - %(message)s'))# 创建一个StreamHandler，用于将日志输出到控制台console_handler = logging.StreamHandler()console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))# 配置root loggerlogging.basicConfig(level=logging.INFO, handlers=[file_handler, console_handler])from chatbot import DingtalkChatbot# 配置 DingTalk 消息通知webhook = &quot;https://oapi.dingtalk.com/robot/send?access_token={机器人TOKEN}&quot;secret = &quot;SEC开头密钥&quot;dd = DingtalkChatbot(webhook, secret=secret, fail_notice=True)private_rpc_url = &quot;http://私有节点ip:8545/&quot;# 公共节点public_rpc_urls = [ &quot;https://bsc-dataseed.binance.org&quot;, &quot;https://bsc-dataseed1.defibit.io&quot;, &quot;https://bsc-dataseed1.binance.org&quot;, &quot;https://bsc-dataseed2.defibit.io&quot;, &quot;https://bsc-dataseed3.ninicoin.io&quot;]def get_ethereum_block_height(rpc_url): start_time = time.time() # 记录开始时间 web3 = Web3(Web3.HTTPProvider(rpc_url)) block_height = web3.eth.block_number end_time = time.time() # 记录结束时间 elapsed_time = end_time - start_time logging.info(f&quot;节点 {rpc_url} 当前区块高度: {block_height}，查询耗时: {elapsed_time:.3f}秒&quot;) return block_heightdef send_dingtalk_message(message): dd.send_text(msg=message)def monitor_block_height(private_rpc_url, public_rpc_urls): inspection_timer = 0 # 初始化巡检计时器，单位为秒 while True: try: my_block_height = get_ethereum_block_height(private_rpc_url) # 获取所有节点的区块高度 public_block_heights = [get_ethereum_block_height(url) for url in public_rpc_urls] logging.info(f&quot;私有节点高度:{my_block_height} 所有节点的区块高度: {public_block_heights}&quot;) # 找到最大的区块高度 max_block_height = max(public_block_heights) logging.info(f&quot;最大区块高度: {max_block_height}&quot;) # 比对节点是否领先 # 如果私有节点的区块高度小于最大区块高度，并且区块差异大于3 则发送警告 diff_height = max_block_height - my_block_height if my_block_height &lt; max_block_height and diff_height &gt; 3: # if my_block_height &lt; max_block_height: currentTime = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) message = f&quot;{app_name}私有节点 {my_block_height} 低于于其他节点，最大区块高度为 {max_block_height}，差异:{diff_height} 时间 {currentTime}&quot; logging.warning(message) # 使用警告级别的日志 send_dingtalk_message(message) if can_call: stop_event_trigger.pin_point_and_stop_engine_event() # 每隔10分钟发送一次巡检记录 if inspection_timer &gt;= 1800: currentTime = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()) inspection_message = f&quot;{app_name} 巡检记录：私有节点 {my_block_height}，&quot; inspection_message += f&quot;公共节点最大区块高度: {max_block_height}，&quot; inspection_message += f&quot;时间 {currentTime}&quot; logging.info(inspection_message) send_dingtalk_message(inspection_message) inspection_timer = 0 # 重置计时器 except Exception as e: logging.error(f&quot;发生错误：{e}&quot;) time.sleep(5) inspection_timer += 5 # 每次循环增加计时器的时间，单位为秒if __name__ == &quot;__main__&quot;: # 读取命令行传入参数 if len(sys.argv) &gt; 1: app_name = sys.argv[1] if app_name is None: app_name = &quot;block_monitor&quot; if len(sys.argv) &gt; 2: canCall = sys.argv[2] if canCall is None: canCall = False if can_call: stop_event_trigger.pin_point_and_stop_engine_event(app_name) logging.info(f&quot;app_name: {app_name}&quot;) t = threading.Thread(target=monitor_block_height, args=(private_rpc_url, public_rpc_urls)) t.start() t.join() 启动脚本 1234567891011121314#!/bin/bash# 增加一个启动参数，app_name,如传入则使用传入的app_name，并加入到启动命令中app_name=$1# 设置启动日志文件路径start_log_file=&quot;logs/start_script.log&quot;# 启动 Python 脚本，并将输出保存到启动日志文件nohup python3.10 monitor.py $app_name &gt; $start_log_file 2&gt;&amp;1 &amp;# 获取启动的 Python 进程的PID并保存到文件中echo $! &gt; pid_file.txtecho &quot;脚本已在后台运行。PID为：$(cat pid_file.txt)&quot; 停止脚本 12345678910111213141516#!/bin/bash# 获取之前保存的PID文件pid_file=&quot;pid_file.txt&quot;pid=$(cat $pid_file 2&gt;/dev/null)if [ -z &quot;$pid&quot; ]; then echo &quot;未找到PID。脚本可能未在运行。&quot;else # 终止Python进程 kill -TERM $pid echo &quot;PID为 $pid 的脚本已停止。&quot; # 删除PID文件 rm $pid_filefi","link":"/zh-CN/node-monitor/"},{"title":"OO模块集成 Jetcache 缓存问题","text":"活动Action开发过程中碰到缓存使用的问题，Action中的代码基本从原 service 中迁移，Jetcache 缓存的注解对Spring 容器内的类生效（现在代码中都作用在@service标记类中），但像Action 这些类手动创建出来实例缓存注解就失效了； 思路1： 简单有效的方式，通过显式的 Api 调用来集成，通过抽象类定义存取缓存基础动作，子类显式调用，这种思路下搞到缓存入口CacheManager就行，配合官方demo。代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class AbstractActivityHandlerFacility { protected CacheManager getCacheManager() { return SpringUtil.getBean(CacheManager.class); } private Cache&lt;String, Object&gt; caches; public AbstractActivityHandlerFacility() { QuickConfig qc = QuickConfig.newBuilder(&quot;userCache&quot;) .expire(Duration.ofSeconds(3600)) .loader(this::loadOrderSumFromDatabase) .refreshPolicy(RefreshPolicy.newPolicy(60, TimeUnit.SECONDS).stopRefreshAfterLastAccess(100, TimeUnit.SECONDS)) .penetrationProtect(true) .build(); caches = getCacheManager().getOrCreateCache(qc); } protected String getCacheKey(String constantPrefix, ActivityContext context) { return new StringBuilder(constantPrefix) .append(context.getActivityInstance().getActivityCombineInfo().getActivityBaseInfo().getId()) .append(&quot;_&quot;) .append(context.getUserInstance().getUserId()).toString(); } protected RedisService getRedisService() { return SpringUtil.getBean(RedisService.class); } protected void putToCache(String key, Object value, long timeout, TimeUnit timeUnit) { caches.put(key, value, timeout, timeUnit); } protected &lt;T&gt; T getCache(String key) { return (T) caches.get(key); } protected void clearCache(String key) { caches.remove(key); }} 备注： QuickConfig 是jetcache 2.7.x 版本才有， 项目中v2.6.7业务代码中手动调用存取数据，代码量多了50%，同时增加了编码的思维负担。 1234567891011121314151617181920212223242526public ActivityCombineInfo getJoinActivityStatus() { String cacheKey = getCacheKey(CacheConstant.ACTIVITY_USER_JOIN_INFO, context); log.info(&quot;getJoinActivityStatus cacheKey: {}&quot;, cacheKey); ActivityCombineInfo cache = getCache(cacheKey); if (cache == null) { log.info(&quot;Get join activity status from cache, cacheKey: {}&quot;, cacheKey); JoinStatusAction joinStatusAction = getJoinStatusAction(); ActivityCombineInfo&lt;JoinActivityResponse&gt; execute = null; try { execute = joinStatusAction.execute(context); // Put Cache putToCache(cacheKey, execute, 60, TimeUnit.SECONDS); } catch (ActivityActionException e) { log.error(&quot;Join status execute failed: {}&quot;, e.getMessage()); } return execute; } return cache; } 思路1能达到要求，但不够优雅，万不得已情况下实在难以接受。 思路2（目前采用）：不打破现有cache 的编码使用习惯，Action 中可以直接使用@Cached、@CacheInvalidate等注解。要做到这种程度还是要将Action 调用方 ActivityHandler和容器勾搭上，看看代码找找思路。 过程spring 容器下注解工作套路，容器生命周期的钩子中触发扫 package-&gt;反射-&gt;挂切面-&gt;动态代理目标对象。盲猜 jetcache 也差不多，只是时机的选择问题。考古一张spring 的图 源码解读： Maven: com.alicp.jetcache:jetcache-anno:2.6.7 注解工作代码 Maven: com.alicp.jetcache:jetcache-anno-api:2.6.7 注解声明 Maven: com.alicp.jetcache:jetcache-core:2.6.7 核心实现，没什么和spring相关内容 Maven: com.alicp.jetcache:jetcache-autoconfigure:2.6.7 springboot 自动装配套路 Maven: com.alicp.jetcache:jetcache-redis:2.6.7 Maven: com.alicp.jetcache:jetcache-starter-redis:2.6.7 撸了下代码，跟预想差不多 CreateCacheAnnotationBeanPostProcessor，作为时机 开始初始化缓存注解相关的内容； 层次依次： CacheAdvisor -&gt; CachePointcut -&gt;JetCacheInterceptor 有这三个就具备 aop 条件了。 关键代码：通过ProxyFactory动态将CacheAdvisor织入activityHandler 12345678910public &lt;T&gt; T dynamicCreateActivityHandler(ActivityHandler activityHandler){ ProxyFactory factory = new ProxyFactory(); factory.setTarget(activityHandler); factory.addAdvisor(SpringUtil.getBean(CacheAdvisor.class)); // Error: Set 'exposeProxy' property on Advised to 'true' to make it available, and ensure that AopContext.currentProxy() is invoked in the same thread as the AOP invocation context. // 设置显式暴露后，AopContext.currentProxy()才能正常使用 factory.setExposeProxy(true); //factory.setInterfaces(JetCacheInterceptor.class); return (T) factory.getProxy();} 调用方式和原来service中一样 1234567891011121314151617181920212223242526public class ActionsHandler implements Handler {//省略 private ActionsHandler _this() { return (ActionsHandler) AopContext.currentProxy(); } @Override public boolean doJoinActivity() { return _this()._doJoinActivity(context); } @CacheInvalidate(name = CacheConstant.ACTIVITY_USER_JOIN_INFO, key = &quot;#context.activityInstance.activityCombineInfo.activityBaseInfo.id + '_' + #context.userInstance.userId&quot; ) private boolean _doJoinActivity(ActivityContext context){ DoJoinAction doJoinAction = getDoJoinAction(); try { return doJoinAction.execute(context); } catch (ActivityActionException e) { log.error(&quot;Do Join execute failed: {}&quot;, e.getMessage()); } return false; } } 区别是多绕2个弯，原接口doJoinActivity()设计时考虑灵活性，没使用形参而是使用实例成员作为参数，注解中的 key 无法动态计算#userId这种变量翻了解析逻辑，关键代码ExpressionUtil.eval:61 ，这块看似留了KeyEvaluator作口子用来扩展，但是没有给上下文修Context改的空间，翻了一圈，无计可施。 目前取巧暂时用内部方法包装context，凑合先用，种草 后续来拔。","link":"/zh-CN/jetcache-integration/"},{"title":"python networkx","text":"networkx networkx是一个用Python语言开发的图论与复杂网络建模工具,利用networkx可以以标准化和非标准化的数据格式存储网络、生成多种随机网络和经典网络、分析网络结构、建立网络模型、设计新的网络算法、进行网络绘制等。networkx支持创建简单无向图、有向图和多重图（multigraph）;内置许多标准的图论算法，节点可为任意数据；支持任意的边值维度，功能丰富，简单易用 新套利引擎使用 networkx 来实现.基本目标: 给出任意2个 currency, 计算两个 currency 之间的利润最大的交易路径(跨cex) 基础的图结构 Graph：无多重边无向图 DiGraph：无多重边有向图 MultiGraph：有多重边无向图 MultiDiGraph：有多重边有向图 问题点 基础结构的选择 用什么来作为node 的weight 哪些可以作为 edge 技术栈 Python3.12 ccxt pandas asyncio configparser sqlalchemy loguru redis pytz networkx aiomonitor fastapi uvicorn websockets 程序目录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120.├── Readme-dev.md├── Readme.md├── __init__.py├── alert│ ├── __init__.py│ ├── alert_manager.py│ └── chatbot.py├── bugs.md├── build.sh├── config│ ├── __init__.py│ ├── config.ini│ ├── config_dev.ini│ ├── config_loader.py│ ├── config_prod.ini│ └── gateio-bsc.json├── core│ ├── __init__.py│ ├── arbitrage_opportunity_finder.py│ ├── graph_builder.py│ ├── path_finder.py│ ├── profit_calculator.py│ └── simple_opportunity_finder.py├── daily_report.py├── data│ ├── __init__.py│ ├── binance_data_fetcher.py│ ├── bitget_data_fetcher.py│ ├── bithumb_data_fetcher.py│ ├── bybit_data_fetcher.py│ ├── coin_mapping.py│ ├── data_collector.py│ ├── data_collector_mp.py│ ├── data_launcher.py│ ├── data_launcher_mp.py│ ├── gate_data_fetcher.py│ ├── huobi_data_fetcher.py│ ├── kucoin_data_fetcher.py│ ├── lbank_data_fetcher.py│ ├── mexc_data_fetcher.py│ ├── okx_data_fetcher.py│ ├── process_manager.py│ ├── redis_data_store.py│ ├── redis_monitor.py│ ├── test_coin_mapping.py│ ├── upbit_data_fetcher.py│ ├── utils.py│ ├── whitebit_data_fetcher.py│ └── xt_data_fetcher.py├── db.py├── dev.sh├── exchanges│ ├── __init__.py│ ├── ext│ │ ├── __init__.py│ │ ├── ext_bithumb.py│ │ ├── gate_ext.py│ │ ├── gate_ext_no_sync.py│ │ ├── test_bithumb.py│ │ ├── test_gate.py│ │ └── upbit.py│ └── initialize.py├── img│ ├── bithumb-menu.png│ ├── left-menu-0.png│ ├── left-menu-1.png│ └── readme.md├── korean_coin_carry.egg-info│ ├── PKG-INFO│ ├── SOURCES.txt│ ├── dependency_links.txt│ ├── requires.txt│ └── top_level.txt├── main.py├── mev-bot.sol├── requirements.txt├── setup.py├── start.sh├── stop.sh├── symbols.db├── test│ ├── __init__.py│ ├── symbols.db│ ├── test_ai.py│ ├── test_ai_2.py│ ├── test_alert.py│ ├── test_arbitrage_graph.py│ ├── test_asyncio.py│ ├── test_asyncio_2.py│ ├── test_binance.py│ ├── test_bithumb.py│ ├── test_config.py│ ├── test_core.py│ ├── test_currency_conversion.py│ ├── test_data_collector.py│ ├── test_gateio.py│ ├── test_many_exchange_fetch_ticker.py│ ├── test_many_exchange_fetch_ticker2.py│ ├── test_math.py│ ├── test_multiprocessing.py│ ├── test_networkx.py│ ├── test_redis.py│ ├── test_symbols.py│ ├── test_symbols_to_db.py│ ├── test_tg-bot.py│ ├── test_triangle.py│ ├── test_upbit.py│ ├── test_upbit_private.py│ ├── test_withdraw_deposit.py│ └── upbit_gateio_intersection.csv├── trade│ └── celery_config.py└── web ├── app.py └── static └── index.html 界面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469import networkx as nxfrom loguru import loggerimport datetimeimport tracebackimport jsonfrom data.redis_data_store import RedisDataStorageclass SimpleArbitrageGraph: # 默认的交易所手续费配置 DEFAULT_FEE_CONFIG = { 'binance': {'buy': 0.001, 'sell': 0.001, &quot;withdraw&quot;: 0.001}, # Binance 现货手续费率 'upbit': {'buy': 0.0004, 'sell': 0.0004, &quot;withdraw&quot;: 0.001}, # Upbit 现货手续费率 'bithumb': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, # Bithumb 现货手续费率 'gate': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'okx': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'mexc': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'bitget': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'bybit': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'xt': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'lbank': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, 'huobi': {'buy': 0.002, 'sell': 0.002, &quot;withdraw&quot;: 0.001}, } def __init__(self, fee_config=None): &quot;&quot;&quot; 初始化套利图构建器 fee_config: 交易所手续费配置字典，如果不传入则使用默认配置 &quot;&quot;&quot; self.fee_config = fee_config if fee_config is not None else self.DEFAULT_FEE_CONFIG self.graph = nx.MultiDiGraph() # 使用多重有向图 self.opportunity_durations = {} # 用于记录套利机会的持续时间 self.redis_client = RedisDataStorage() def addOrUpdateEdge(self, from_currency, to_currency, price, exchange, orderbook=None): &quot;&quot;&quot; 添加或更新交易对（边）到图中 from_currency: 起始币种 to_currency: 目标币种 price: 当前交易对的价格 exchange: 交易所名称 orderbook: 订单簿数据，格式为：{ 'bids': [(price, amount), ...], # 买单列表，按价格降序 'asks': [(price, amount), ...], # 卖单列表，按价格升序 'timestamp': timestamp # 订单簿时间戳 } &quot;&quot;&quot; # 获取当前交易所的买入和卖出手续费 fee = self.fee_config[exchange]['buy'] + self.fee_config[exchange]['sell'] # 准备边的属性 edge_data = { 'weight': price, 'fee': fee, 'exchange': exchange, 'key': exchange, 'orderbook': None } # 如果提供了orderbook数据，添加到边的属性中并计算统计信息 if orderbook: bids = orderbook['bids'] asks = orderbook['asks'] # 计算bids的统计信息 try: bids_total_volume = sum(amount for _, amount in bids) bids_weighted_price = sum(price * amount for price, amount in bids) / bids_total_volume if bids_total_volume &gt; 0 else 0 except Exception as e: logger.error(f&quot;Error calculating bids stats: {e}&quot;) logger.error(f&quot;{exchange} {from_currency} - {to_currency} {bids}&quot;) # 计算asks的统计信息 asks_total_volume = sum(amount for _, amount in asks) asks_weighted_price = sum(price * amount for price, amount in asks) / asks_total_volume if asks_total_volume &gt; 0 else 0 edge_data['orderbook'] = { 'bids': bids, 'asks': asks, 'timestamp': orderbook.get('timestamp', None), 'stats': { 'bids': { 'total_volume': bids_total_volume, 'weighted_price': bids_weighted_price }, 'asks': { 'total_volume': asks_total_volume, 'weighted_price': asks_weighted_price } } } logger.debug(f&quot;Added orderbook stats info:{edge_data['orderbook']}&quot;) # 如果边已存在，更新它 if self.graph.has_edge(from_currency, to_currency): for edge in self.graph[from_currency][to_currency].values(): if edge['exchange'] == exchange: # 更新基本属性 edge['weight'] = price edge['fee'] = fee # 确保orderbook字段存在 if 'orderbook' not in edge: edge['orderbook'] = {} # 更新orderbook数据 if orderbook: edge['orderbook'] = edge_data['orderbook'] logger.debug(f&quot;Updated edge from {from_currency} to {to_currency}: price = {price}, fee = {fee}, exchange = {exchange}&quot;) return # 如果边不存在，添加新边 self.graph.add_edge(from_currency, to_currency, **edge_data) logger.debug(f&quot;Added edge from {from_currency} to {to_currency}: price = {price}, fee = {fee}, exchange = {exchange}&quot;) def calculate_cross_exchange_arbitrage(self, base_currency, quote_currency, intermediate_currency, amount, cex_a, cex_b): &quot;&quot;&quot; 计算跨交易所套利机会 base_currency: 基础币种（如BTC） quote_currency: 报价币种（如USDT） intermediate_currency: 中间币种（如KRW） amount: 交易金额（以quote_currency计价） cex_a: 交易所A的名称 cex_b: 交易所B的名称 return: (套利机会详细信息字典, 套利路径描述) &quot;&quot;&quot; # 检查交易所A中是否存在直接交易对 if not self.graph.has_edge(base_currency, quote_currency): logger.debug(f&quot;在交易所{cex_a}中未找到{base_currency}/{quote_currency}交易对&quot;) return None, &quot;&quot;,&quot;&quot; # 在交易所A中计算可以买入的base_currency数量 base_amount = None cost_in_a = amount cost_edge = None cost_counter_price = None for edge in self.graph[base_currency][quote_currency].values(): if edge['exchange'] == cex_a: # 检查orderbook数据 if 'orderbook' in edge and edge['orderbook'] and 'asks' in edge['orderbook'] : # 获取asks的统计数据 asks_stats = edge['orderbook']['stats']['asks'] # 检查是否有足够的卖单深度 if asks_stats['total_volume'] &lt; amount: logger.warning(f&quot;订单深度不足：需要{amount} {quote_currency}，但只有{asks_stats['total_volume']} {quote_currency}的深度&quot;) return None, &quot;&quot;,&quot;&quot; # 使用加权平均价格计算可买入数量 weighted_price = asks_stats['weighted_price'] cost_counter_price = weighted_price base_amount = amount / (weighted_price * (1 + edge['fee'])) else: cost_counter_price = edge['weight'] # 如果没有orderbook数据，使用普通价格 base_amount = amount / (edge['weight'] * (1 + edge['fee'])) cost_edge = edge logger.debug(f&quot;在{cex_a}中用{amount} {quote_currency}可以买入{base_amount} {base_currency}&quot;) break if base_amount is None: logger.debug(f&quot;在交易所{cex_a}中未找到{base_currency}/{quote_currency}交易对&quot;) return None, &quot;&quot;,&quot;&quot; # 检查交易所B中的转换路径 try: # 第一步：计算在交易所B中将base_currency转换为intermediate_currency base_to_intermediate_edge = None if not self.graph.has_edge(base_currency, intermediate_currency): logger.warning(f&quot;在交易所{cex_b}中未找到{base_currency}/{intermediate_currency}交易对&quot;) return None, &quot;&quot;,&quot;&quot; for edge in self.graph[base_currency][intermediate_currency].values(): if edge['exchange'] == cex_b: base_to_intermediate_edge = edge break if base_to_intermediate_edge is None: logger.warning(f&quot;在交易所{cex_b}中未找到{base_currency}/{intermediate_currency}交易对&quot;) return None, &quot;&quot;,&quot;&quot; # 第二步：计算在交易所B中将intermediate_currency转换为quote_currency intermediate_to_quote_edge = None for edge in self.graph[intermediate_currency][quote_currency].values(): if edge['exchange'] == cex_b: intermediate_to_quote_edge = edge break if intermediate_to_quote_edge is None: logger.warning(f&quot;在交易所{cex_b}中未找到{intermediate_currency}/{quote_currency}交易对&quot;) return None, &quot;&quot;,&quot;&quot; # 打印详细的交易路径信息 logger.debug(f&quot;交易路径详情:&quot;) logger.debug(f&quot;第一步: 在{cex_a}中买入{amount} {base_currency}&quot;) logger.debug(f&quot;第二步: 在{cex_b}中将{base_currency}转换为{intermediate_currency}&quot;) logger.debug(f&quot;第三步: 在{cex_b}中将{intermediate_currency}转换为{quote_currency}&quot;) # 计算在交易所B中的转换后金额 # 第一次转换：base_currency -&gt; intermediate_currency base_to_intermediate_price = None if 'orderbook' in base_to_intermediate_edge and base_to_intermediate_edge['orderbook'] and 'asks' in base_to_intermediate_edge['orderbook']: # 检查bids深度 bids_stats = base_to_intermediate_edge['orderbook']['stats']['bids'] if bids_stats['total_volume'] &lt; base_amount: logger.warning(f&quot;订单深度不足：需要卖出{base_amount} {base_currency}，但只有{bids_stats['total_volume']} {base_currency}的深度&quot;) return None, &quot;&quot;,&quot;&quot; # 使用加权平均价格计算 weighted_price = bids_stats['weighted_price'] base_to_intermediate_price = weighted_price intermediate_amount = base_amount * weighted_price * (1 - base_to_intermediate_edge['fee']) else: base_to_intermediate_price = base_to_intermediate_edge['weight'] intermediate_amount = base_amount * base_to_intermediate_edge['weight'] * (1 - base_to_intermediate_edge['fee']) intermediate_to_quote_price = None # 第二步转换：intermediate_currency -&gt; quote_currency if 'orderbook' in intermediate_to_quote_edge and intermediate_to_quote_edge['orderbook'] and 'asks' in intermediate_to_quote_edge['orderbook']: # 检查bids深度 bids_stats = intermediate_to_quote_edge['orderbook']['stats']['bids'] if bids_stats['total_volume'] &lt; intermediate_amount: logger.warning(f&quot;订单深度不足：需要卖出{intermediate_amount} {intermediate_currency}，但只有{bids_stats['total_volume']} {intermediate_currency}的深度&quot;) return None, &quot;&quot;,&quot;&quot; # 使用加权平均价格计算 weighted_price = bids_stats['weighted_price'] intermediate_to_quote_price = weighted_price final_amount = intermediate_amount * weighted_price * (1 - intermediate_to_quote_edge['fee']) else: intermediate_to_quote_price = intermediate_to_quote_edge['weight'] final_amount = intermediate_amount * intermediate_to_quote_edge['weight'] * (1 - intermediate_to_quote_edge['fee']) # 计算利润（以quote_currency计价） profit = final_amount - cost_in_a profit_percentage = (profit / cost_in_a) * 100 # 构建详细的套利信息字典 arbitrage_info = { 'currencies': { 'base': base_currency, 'quote': quote_currency, 'intermediate': intermediate_currency }, 'exchanges': { 'buy': cex_a, 'sell': cex_b }, 'amounts': { 'initial_quote': amount, 'base': base_amount, 'intermediate': intermediate_amount, 'final': final_amount }, 'profit': { 'amount': profit, 'percentage': profit_percentage } } from_config = self.redis_client.get_data_by_exchange(cex_a, base_currency, &quot;config&quot;) if from_config and 'config' in from_config: networks_info = json.loads(from_config['config']) networks_desc = [] for network in networks_info.get('networks', []): status = [] if network.get('deposit'): status.append('可充值') if network.get('withdraw'): status.append('可提现') if network.get('fee'): status.append(&quot;费用:&quot;+str(network.get(&quot;fee&quot;))) if status: networks_desc.append(f&quot;{network['network']}({', '.join(status)})&quot;) networks_description = ' | '.join(networks_desc) if networks_desc else '无网络信息' else: networks_description = '无网络配置' # 修改路径描述部分 # 构建路径描述，添加数据有效性检查 def get_orderbook_stats(edge, side): if edge and 'orderbook' in edge and edge['orderbook'] and \\ 'stats' in edge['orderbook'] and side in edge['orderbook']['stats']: stats = edge['orderbook']['stats'][side] return f&quot;📊深度: {stats['total_volume']:.8f} 均价: {stats['weighted_price']:.8f}&quot; return &quot;📊深度数据不可用&quot; path_description = ( f&quot;套利路径:\\n&quot; f&quot;步骤1: {cex_a} {base_currency}/{quote_currency} 🔵买入价格={cost_counter_price:.8f} &quot; f&quot;买入{base_amount:.8f} {base_currency}(花费{amount} {quote_currency}) &quot; f&quot;{get_orderbook_stats(cost_edge, 'asks')}\\n&quot; f&quot;步骤2: {cex_b} {base_currency}/{intermediate_currency} 🟢卖出价格={base_to_intermediate_price:.8f} &quot; f&quot;转换得到{intermediate_amount:.8f}{intermediate_currency} &quot; f&quot;{get_orderbook_stats(base_to_intermediate_edge, 'bids')}\\n&quot; f&quot;步骤3: {cex_b} {intermediate_currency}/{quote_currency} 🟢卖出价格={intermediate_to_quote_price:.8f} &quot; f&quot;转换得到{final_amount:.8f}{quote_currency} &quot; f&quot;{get_orderbook_stats(intermediate_to_quote_edge, 'bids')}\\n&quot; f&quot;💰总结: 利润={profit:.8f}{quote_currency} (🔥{profit_percentage:.2f}%)\\n&quot; f&quot;⏰时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}&quot; ) # logger.info(path_description) return arbitrage_info, path_description, networks_description except Exception as e: logger.error(f&quot;计算套利路径时发生错误: {str(e)}, cex_a:{cex_a} base:{base_currency} quote:{quote_currency} cex_b:{cex_b} &quot;) logger.error(f&quot;Error traceback:\\n{traceback.format_exc()}&quot;) return None, &quot;&quot;,&quot;&quot; def find_all_cross_exchange_arbitrage(self, amount=1.0, min_profit_threshold=0.001,exchange_router_config=None): &quot;&quot;&quot; 自动发现所有可能的跨交易所套利机会 amount: 交易金额（以base_currency计价） min_profit_threshold: 最小利润阈值，低于此阈值的套利机会将被忽略 exchange_router_config: 交易所路由配置，格式为：{ 'from_exchanges': ['binance', 'okx'], # 允许的买入交易所列表 'to_exchanges': ['upbit', 'bithumb'] # 允许的卖出交易所列表 } return: 所有可行的套利机会列表 &quot;&quot;&quot; opportunities = [] # 获取所有币种和交易所 currencies = list(self.graph.nodes()) exchanges = list(set(edge['exchange'] for _, _, edge in self.graph.edges(data=True))) # 定义允许的报价币种 allowed_quote_currencies = ['USDT', 'KRW'] # 收集当前有效的套利机会标识 current_opportunities = set() # 遍历所有可能的币种组合和交易所组合 for base_currency in currencies: for quote_currency in allowed_quote_currencies: if base_currency == quote_currency: continue # 遍历配置的交易所组合 for cex_a in exchange_router_config['from_exchanges']: for cex_b in exchange_router_config['to_exchanges']: if cex_a == cex_b: continue # 遍历所有可能的中间币种 # for intermediate_currency in currencies: for intermediate_currency in ['KRW']: if intermediate_currency in [base_currency, quote_currency]: continue # 计算套利机会 profit, path_description,networks_description = self.calculate_cross_exchange_arbitrage( base_currency, quote_currency, intermediate_currency, amount, cex_a, cex_b ) profit_value=profit['profit']['amount'] if profit and profit['profit']['amount'] else 0.00000000 # 生成套利机会的唯一标识 opp_key = f&quot;{base_currency}-{quote_currency}-{intermediate_currency}-{cex_a}-{cex_b}&quot; # 如果利润超过阈值，记录套利机会 # if profit_value and (profit_value / (amount * self.graph[base_currency][quote_currency][cex_a]['weight'])) &gt; min_profit_threshold: # 如果有利润且有路径描述，记录为有效套利机会 show_all_profit = self.redis_client.get_generic_data(&quot;config&quot;, &quot;show_all_profit&quot;) if (show_all_profit or profit_value &gt; 0) and path_description: current_time = datetime.datetime.now() current_opportunities.add(opp_key) # 更新持续时间记录 if opp_key not in self.opportunity_durations: self.opportunity_durations[opp_key] = { 'first_seen': current_time, 'last_seen': current_time, 'duration': 0 } else: self.opportunity_durations[opp_key]['last_seen'] = current_time self.opportunity_durations[opp_key]['duration'] = \\ (current_time - self.opportunity_durations[opp_key]['first_seen']).total_seconds() opportunity = { 'base_currency': base_currency, 'quote_currency': quote_currency, 'intermediate_currency': intermediate_currency, 'cex_a': cex_a, 'cex_b': cex_b, 'profit': profit_value, 'duration': self.opportunity_durations[opp_key]['duration'], 'path_description': path_description, 'network_description': networks_description } opportunities.append(opportunity) logger.info(f&quot;发现新的套利机会：{base_currency}-&gt;{intermediate_currency}-&gt;{quote_currency} | {cex_a}-&gt;{cex_b} | 利润：{profit_value:.8f}&quot;) # 清理已不存在的套利机会记录 expired_opportunities = set(self.opportunity_durations.keys()) - current_opportunities for opp_key in expired_opportunities: del self.opportunity_durations[opp_key] logger.debug(f&quot;移除已消失的套利机会记录：{opp_key}&quot;) # 按利润排序 opportunities.sort(key=lambda x: x['profit'], reverse=True) return opportunities def format_opportunities_to_markdown(self, opportunities): &quot;&quot;&quot; 将套利机会列表转换为markdown格式的字符串 opportunities: 套利机会列表 return: markdown格式的字符串 &quot;&quot;&quot; if not opportunities: return [] # 返回单个套利机会的表格行数据 rows = [] for i, opp in enumerate(opportunities, 1): row = f&quot;| {i} | {opp['base_currency']} | {opp['quote_currency']} | {opp['intermediate_currency']} | &quot; row += f&quot;{opp['cex_a']} | {opp['cex_b']} | {opp['profit']:.8f} {opp['quote_currency']} | {int(opp['duration'])} s |&quot; row += f&quot;{opp['path_description'].replace(&quot;\\n&quot;,&quot;&lt;br&gt;&quot;)} | {opp['network_description']} | &quot; rows.append(row) return rows def analyze_arbitrage_opportunities(self, configs=None): &quot;&quot;&quot; 分析不同配置下的套利机会 configs: 配置列表，每个配置包含 amount（交易金额）和 threshold（利润阈值） 如果不提供，将使用默认配置 return: (是否发现套利机会, 格式化的套利机会描述（markdown格式）) &quot;&quot;&quot; if configs is None: configs = { 'trade':[ {'amount': 1.0, 'threshold': 0.001}, # 标准配置 # {'amount': 0.1, 'threshold': 0.005}, # 小额交易配置 # {'amount': 5.0, 'threshold': 0.0005} # 大额交易配置 ], 'exchange_router':{ 'from_exchanges': ['binance'], # 允许的买入交易所列表 'to_exchanges': ['upbit', 'bithumb'] # 允许的卖出交易所列表 } } all_results = [] for config in configs['trade']: logger.info(f&quot;\\n分析配置：交易金额 = {config['amount']} BTC, 利润阈值 = {config['threshold']*100}%&quot;) opportunities = self.find_all_cross_exchange_arbitrage( amount=config['amount'], min_profit_threshold=config['threshold'], exchange_router_config=configs['exchange_router'] ) # 使用format_opportunities_to_markdown方法获取表格行数据 rows = self.format_opportunities_to_markdown(opportunities) all_results.extend(rows) # 如果没有找到任何套利机会 if not all_results: return False, &quot;未发现任何套利机会。&quot; # 生成表格头部 final_markdown = &quot;| 序号 | 基础币种 | 报价币种 | 中间币种 | 买入Cex | 卖出Cex | 预期利润 | 持续时间 | 详细路径 | 网络信息 |\\n&quot; final_markdown += &quot;|------|----------|----------|----------|---------|---------|----------|------------|------------|---|\\n&quot; # 添加所有套利机会数据 final_markdown += &quot;\\n&quot;.join(all_results) return True, final_markdown","link":"/zh-CN/python_networkx/"},{"title":"python 性能分析","text":"Py-Spy 是一个用于 Python 的性能分析工具，它使用堆栈跟踪来收集和显示 Python 代码的运行时间。 12pip install py-spysudo py-spy top --pid 24816 py-spy dump –pid 24816 123456789101112131415161718192021222324252627282930313233343536Thread 0x7FF8547494C0 (active): &quot;MainThread&quot; main (data_main.py:36) &lt;module&gt; (data_main.py:40) execfile (_pydev_imps/_pydev_execfile.py:18) _exec (pydevd.py:1570) run (pydevd.py:1563) main (pydevd.py:2252) &lt;module&gt; (pydevd.py:2270)Thread 0x700005C81000 (idle): &quot;pydevd.Writer&quot; wait (threading.py:359) get (queue.py:180) _on_run (_pydevd_bundle/pydevd_comm.py:367) run (_pydevd_bundle/pydevd_comm.py:219) _bootstrap_inner (threading.py:1075) _bootstrap (threading.py:1032)Thread 0x700006C84000 (active): &quot;pydevd.Reader&quot; _on_run (_pydevd_bundle/pydevd_comm.py:291) run (_pydevd_bundle/pydevd_comm.py:219) _bootstrap_inner (threading.py:1075) _bootstrap (threading.py:1032)Thread 0x700007C87000 (idle): &quot;pydevd.CommandThread&quot; wait (threading.py:359) wait (threading.py:655) _on_run (pydevd.py:159) run (_pydevd_bundle/pydevd_comm.py:219) _bootstrap_inner (threading.py:1075) _bootstrap (threading.py:1032)Thread 0x700008C8A000 (idle): &quot;Thread-5 (_run_async_loop)&quot; select (selectors.py:566) _run_once (pydevd_asyncio/pydevd_nest_asyncio.py:263) run_until_complete (pydevd_asyncio/pydevd_nest_asyncio.py:234) _run_async_loop (data/data_collector.py:165) run (threading.py:1012) _bootstrap_inner (threading.py:1075) _bootstrap (threading.py:1032) aiomonitor123456789101112131415def _run_async_loop(self, poll_interval): &quot;&quot;&quot; 在独立线程中运行 asyncio 事件循环 &quot;&quot;&quot; try: loop = asyncio.new_event_loop() # 创建新的事件循环 asyncio.set_event_loop(loop) # 设置为当前线程的事件循环 with aiomonitor.start_monitor(loop): loop.run_until_complete(self._start_async_polling(poll_interval)) logger.info(&quot;[INFO] Async loop stopped.&quot;) except Exception as e: logger.error(f&quot;[ERROR] Async loop encountered an error: {e}&quot;) logger.info(&quot;[INFO] Restarting async loop...&quot;) 运行 进行交互 1python -m aiomonitor.cli","link":"/zh-CN/python_py_spy/"},{"title":"Carry-Coin 记服务迁移和流量优化","text":"最近Contabo服务器频繁死机，发邮件给官方反应问题，一开始嘴硬说没问题让自查，沟通2天又是截图又是各种开票，最后承认问题说技术团队排查但是不给解决时间 邮件回复 VNC过去看到 sda3硬盘一直挂不上/dev/sda3: recovering journal，猜测不是硬件存储坏了就是虚拟化平台抽风；好在重启5-8次大概能进系统一次，赶紧拷数据闪人； 目前部署架构 原来contabo的机器8u24g,32TTraffic一个月$26, 相同配置国内厂商看了一圈没有羊毛，最后选择tx，但是相同配置明显贵上天，只能调整架构先开台低配2u4g/90ssd轻量服务器,把front、server、db弄回来，worker后面再说； 程序迁移后大问题没有，每种不足就是出口流量太吃紧了，轻量应用流量包只有2T,跑了10个小时流量80多G，一天毛估估200G； 优化过程iftop大概观察下流量去向，其实心里也有数，整机对外一个是通过nginx访问的front 这是给自己看的前端,还有一个就是mysql,几个worker每秒多线程读写，这部分传输过程中流量花费巨大；资源的话cpu的使用率基本维持在50左右，内存40%左右，优化空间还是有的 jeecgboot 前端肿的不行，所以nginx gzip该压的压起来,改了后观察监控发现提升可以忽略不计。 mysql是大头，这块翻了一些优化料大部分都是持久化侧的，表压缩之类的；所以换了个思路，既然是传输过程中的损耗那么大概率是jdbc驱动的事情，这么常规的场景应该有支持； 翻了mysql-connector-j-8.0.33.jar代码发现果然有戏com.mysql.cj.protocol.a.NativeProtocol中有个字段useCompression开启后mysql的传输过程会压缩，但是默认是关闭的，可以在jdbc连接字符串后面加上useCompression=true来开启压缩； CompressedPacketSender开关打开后会使用com.mysql.cj.protocol.a.CompressedPacketSender来发送数据； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * Packet sender implementation for the compressed MySQL protocol. For compressed transmission of multi-packets, split the packets up in the same way as the * uncompressed protocol. We fit up to MAX_PACKET_SIZE bytes of split uncompressed packet, including the header, into an compressed packet. The first packet * of the multi-packet is 4 bytes of header and MAX_PACKET_SIZE - 4 bytes of the payload. The next packet must send the remaining four bytes of the payload * followed by a new header and payload. If the second split packet is also around MAX_PACKET_SIZE in length, then only MAX_PACKET_SIZE - 4 (from the * previous packet) - 4 (for the new header) can be sent. This means the payload will be limited by 8 bytes and this will continue to increase by 4 at every * iteration. * * @param packet * data bytes * @param packetLen * packet length * @param packetSequence * sequence id * @throws IOException * if i/o exception occurs */ public void send(byte[] packet, int packetLen, byte packetSequence) throws IOException { this.compressedSequenceId = packetSequence; // short-circuit send small packets without compression and return if (packetLen &lt; MIN_COMPRESS_LEN) { writeCompressedHeader(packetLen + NativeConstants.HEADER_LENGTH, this.compressedSequenceId, 0); writeUncompressedHeader(packetLen, packetSequence); this.outputStream.write(packet, 0, packetLen); this.outputStream.flush(); return; } if (packetLen + NativeConstants.HEADER_LENGTH &gt; NativeConstants.MAX_PACKET_SIZE) { this.compressedPacket = new byte[NativeConstants.MAX_PACKET_SIZE]; } else { this.compressedPacket = new byte[NativeConstants.HEADER_LENGTH + packetLen]; } PacketSplitter packetSplitter = new PacketSplitter(packetLen); int unsentPayloadLen = 0; int unsentOffset = 0; // loop over constructing and sending compressed packets while (true) { this.compressedPayloadLen = 0; if (packetSplitter.nextPacket()) { // rest of previous packet if (unsentPayloadLen &gt; 0) { addPayload(packet, unsentOffset, unsentPayloadLen); } // current packet int remaining = NativeConstants.MAX_PACKET_SIZE - unsentPayloadLen; // if remaining is 0 then we are sending a very huge packet such that are 4-byte header-size carryover from last packet accumulated to the size // of a whole packet itself. We don't handle this. Would require 4 million packet segments (64 gigs in one logical packet) int len = Math.min(remaining, NativeConstants.HEADER_LENGTH + packetSplitter.getPacketLen()); int lenNoHdr = len - NativeConstants.HEADER_LENGTH; addUncompressedHeader(packetSequence, packetSplitter.getPacketLen()); addPayload(packet, packetSplitter.getOffset(), lenNoHdr); completeCompression(); // don't send payloads with incompressible data if (this.compressedPayloadLen &gt;= len) { // combine the unsent and current packet in an uncompressed packet writeCompressedHeader(unsentPayloadLen + len, this.compressedSequenceId++, 0); this.outputStream.write(packet, unsentOffset, unsentPayloadLen); writeUncompressedHeader(lenNoHdr, packetSequence); this.outputStream.write(packet, packetSplitter.getOffset(), lenNoHdr); } else { sendCompressedPacket(len + unsentPayloadLen); } packetSequence++; unsentPayloadLen = packetSplitter.getPacketLen() - lenNoHdr; unsentOffset = packetSplitter.getOffset() + lenNoHdr; resetPacket(); } else if (unsentPayloadLen &gt; 0) { // no more packets, send remaining unsent data addPayload(packet, unsentOffset, unsentPayloadLen); completeCompression(); if (this.compressedPayloadLen &gt;= unsentPayloadLen) { writeCompressedHeader(unsentPayloadLen, this.compressedSequenceId, 0); this.outputStream.write(packet, unsentOffset, unsentPayloadLen); } else { sendCompressedPacket(unsentPayloadLen); } resetPacket(); break; } else { // nothing left to send (only happens on boundaries) break; } } this.outputStream.flush(); // release reference to (possibly large) compressed packet buffer this.compressedPacket = null; } 整体思路高效地发送数据包，无论是小包还是大包，同时通过压缩减少传输数据的大小。它通过拆分、压缩和适当的序列管理确保数据完整和顺序发送. 改了以后程序跑起来，超出预期,流量消耗少了近50%，代价是cpu提了10%左右，划算。 先跑着一个月后再看。","link":"/zh-CN/traffic_optimization_idea/"},{"title":"zsh 主题 conda 标签失效","text":"miniconda安装完后，zsh命令行主题不显示conda的环境name 编辑主题文件 vim ~/.oh-my-zsh/themes/bullet-train.zsh-theme 12345678910111213# Virtualenv: current working virtualenvprompt_virtualenv() { local virtualenv_path=&quot;$VIRTUAL_ENV&quot; # 加入Conda环境变量判断逻辑 if [[ -n $CONDA_DEFAULT_ENV &amp;&amp; -n $VIRTUAL_ENV_DISABLE_PROMPT ]]; then prompt_segment $BULLETTRAIN_VIRTUALENV_BG $BULLETTRAIN_VIRTUALENV_FG $BULLETTRAIN_CONDA_PREFIX&quot; $(basename $CONDA_DEFAULT_ENV)&quot; elif [[ -n $virtualenv_path &amp;&amp; -n $VIRTUAL_ENV_DISABLE_PROMPT ]]; then prompt_segment $BULLETTRAIN_VIRTUALENV_BG $BULLETTRAIN_VIRTUALENV_FG $BULLETTRAIN_VIRTUALENV_PREFIX&quot; $(basename $virtualenv_path)&quot; elif which pyenv &amp;&gt; /dev/null; then prompt_segment $BULLETTRAIN_VIRTUALENV_BG $BULLETTRAIN_VIRTUALENV_FG $BULLETTRAIN_VIRTUALENV_PREFIX&quot; $(pyenv version | sed -e 's/ (set.*$//' | tr '\\n' ' ' | sed 's/.$//')&quot; fi} 修改保存. vim ~/.zshrc 1234567# prompt变量中增加BULLETTRAIN_PROMPT_ORDER=( virtualenv #加上 time dir git) 执行source ~/.zshrc","link":"/zh-CN/zsh_add_conda_env_name/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Architecture","slug":"Architecture","link":"/tags/Architecture/"},{"name":"日志清理","slug":"日志清理","link":"/tags/%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86/"},{"name":"jasypt","slug":"jasypt","link":"/tags/jasypt/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"ComfyUI","slug":"ComfyUI","link":"/tags/ComfyUI/"},{"name":"miniconda","slug":"miniconda","link":"/tags/miniconda/"},{"name":"Freebie hunting","slug":"Freebie-hunting","link":"/tags/Freebie-hunting/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"PID","slug":"PID","link":"/tags/PID/"},{"name":"进程管理","slug":"进程管理","link":"/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"HummingBot","slug":"HummingBot","link":"/tags/HummingBot/"},{"name":"Internet Computer","slug":"Internet-Computer","link":"/tags/Internet-Computer/"},{"name":"IC","slug":"IC","link":"/tags/IC/"},{"name":"NockChain","slug":"NockChain","link":"/tags/NockChain/"},{"name":"bsc","slug":"bsc","link":"/tags/bsc/"},{"name":"Jetcache","slug":"Jetcache","link":"/tags/Jetcache/"},{"name":"optimization","slug":"optimization","link":"/tags/optimization/"},{"name":"zsh","slug":"zsh","link":"/tags/zsh/"}],"categories":[{"name":"CarryCoin","slug":"CarryCoin","link":"/categories/CarryCoin/"},{"name":"ComfyUI","slug":"ComfyUI","link":"/categories/ComfyUI/"},{"name":"Freebie hunting","slug":"Freebie-hunting","link":"/categories/Freebie-hunting/"},{"name":"HummingBot","slug":"HummingBot","link":"/categories/HummingBot/"},{"name":"NockChain","slug":"NockChain","link":"/categories/NockChain/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"}],"pages":[{"title":"","text":"google-site-verification: googlea7f41c35f95da755.html","link":"/googlea7f41c35f95da755"},{"title":"About Me","text":"姓名 Gavin性别 男工作经验 10years+学历 本科学校 北京航空航天大学 - 计算机科学与技术邮箱 blackjackhoho@gmail.comTelegram @blackjackhohoGithub https://github.com/konbluesky 14年的老开发,在寻找一个激情、开放、和谐的团队，与志同道合的伙伴共同创造卓越的项目。 基础技能 精通Java,多年的企业级Java程序开发经验,具备完善的架构理论,对各类开源框架有Cover和Hack能力; 熟悉原生HDP、CDH大数据平台，以及大数据场景下各种架构：Lambda、Kappa、微服务等架构，在满足高性能，高可用性，可扩展，安全性等架构特性方面有丰富的经验； 熟练使用Nodejs、Python、Shell等动态语言,能够灵活运用这些语言解决项目中的碎片化问题,如原型验证、数据处理、自动化脚本等； 擅长OOP&amp;OOD,熟悉UML有复杂系统0-1设计和1-N的重构经验； 熟悉DevOPS，SRE，测试体系的搭建，包括TDD开发流程，CI/CD、自动化测试，监控与报警系统，故障排查及快速响应机制 热爱开源项目。 Web3技能 有EVM、Hyperladger Fabric、Sonala的网络建设经验； 有dApps开发经验，熟悉EVM的常用开发库web3j、web3.js、ether.js,hardhat,openzeppelin; 熟悉常见的共识算法PoW，PoS, BFT; 熟悉常用量化策略（AR，TF，MR，SA，MM）,了解Hummingbot等开源量化框架 熟悉各类DeFi产品，如Uniswap v2/v3协议、PancakeSwap； 熟悉各类Cex API; Web2技能 Web开发: SpringBoot、SpringMvc、JFinal、Nginx、Tomcat、Jetty、Django、Flask ORM: Mybatis、Hibernate、JPA, 网络协议: Mqtt、TCP/IP、HTTP1/2、DNS、SSH、WebSocket 数据存储: SQL(Oracle、DB2、Mysql、H2、SQLite),NoSQL(Redis、LevelDb) 消息队列: RabbitMQ、Kafka、RocketMQ 微服务: SpringCloud 容器化: K8s、Docker 操作系统: Macos,Centos,ubuntu 项目MemeSniperFour.meme Token发射跟单交易系统框架: Python,web3,orjson,pydantic功能: 支持 Token 一键发射、镜像发射。 支持 抢买、跟单、抢卖，以及匹配订单规则设置。 Cex&lt;-&gt;Cex 多路径套利监控系统基于NetworkX 多重有向图实时计算,不同Cex之间不同币种的套利机会监控程序接入交易所: Upbit,Bithumb,Binance,Gateio,Bitget,Bybit框架: Python,NetworkX,CCXT,Redis功能: 支持以KRW,BNB,ETH为主要计价交易对之间的三角套利机会和多路径套利机会的发现程序 Cex&lt;-&gt;Cex 资金费率套利系统框架: Python,web3,orjson,pydantic Cex&lt;-&gt;Dex Token全自动套利程序基于Java的分布式架构的token套利程序，目前覆盖网络：Solana、EVM（L1/L2）主要使用AR策略，去中心化交易所（DEX）和中心化交易所（CEX）之间的价格差异实现套利交易。目前Cex支持binanace,okex,mexc,gateio,xt;Dex支持主要链bsc(UniswapV2/3,PancakeV2/3),Solana,odos； carry-config-generator(python) 技术栈:web3,pandas ; 工程主要负责根据dex,cex，第三方：1inch,odos,dexscreener 数据，进行数据分析最终生成套利配置； carry-core (Java) 技术栈：Jdk17,Maven,Spring,Rxjava,Guava 一个基于Java的套利核心程序，dex&lt;-&gt;cex套利逻辑的顶层抽象SwapEngine，SwapStategy, ArbitrageProcessor,CenterExchange,DecenterExchanage,SwapProtocol 等; carry-worker (Java) 技术栈: Springboot3.2.5,Xchange,Web3j,RxJava3,Guava等； 工程基于core实现的不同dex,cex的监控、dd告警、dd通知、全自动买卖逻辑； 性能表现 Metric Value Average RT &lt; 50ms Concurrency 150-200 TPS 1200 - 1500 requests/sec CPU Utilization ≈ 95% RAM Usage ≈ 90% High IO 500MB/s read/write Error Rate &lt; 0.1% carry-protocol-adapter(Nodejs) 基于Uniswap-sdk ,jupiter-swap-api(solana)开发的套利协议适配器，适配v2/v3询价； carry-web-front (Nodejs) 技术栈: Vue3.0+TypeScript+Vite5+Ant-Design-Vue等 工程主要管理平台的前端页面，包括套利开关、线上配置、交易数据监控，链上数据监控报表等； carry-web-server (Java) 技术栈: Spring Cloud Alibaba, Mysql, 管理平台的后端服务；","link":"/about/"}]}